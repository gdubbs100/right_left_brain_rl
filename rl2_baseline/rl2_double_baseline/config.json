{
  "num_frames": 50000000,
  "max_rollouts_per_task": 10,
  "exp_label": "ml3_rl2_baseline_run",
  "env_name": "ML3-v2",
  "disable_decoder": true,
  "disable_kl_term": true,
  "add_nonlinearity_to_latent": true,
  "rlloss_through_encoder": true,
  "latent_dim": 256,
  "pass_state_to_policy": false,
  "pass_latent_to_policy": true,
  "pass_belief_to_policy": false,
  "pass_task_to_policy": false,
  "policy_state_embedding_dim": null,
  "policy_latent_embedding_dim": null,
  "policy_belief_embedding_dim": null,
  "policy_task_embedding_dim": null,
  "norm_state_for_policy": false,
  "norm_latent_for_policy": false,
  "norm_belief_for_policy": false,
  "norm_task_for_policy": false,
  "norm_rew_for_policy": true,
  "norm_actions_pre_sampling": false,
  "norm_actions_post_sampling": false,
  "policy_layers": [
    512
  ],
  "policy_activation_function": "tanh",
  "policy_initialisation": "normc",
  "policy_anneal_lr": false,
  "policy": "ppo",
  "policy_optimiser": "adam",
  "ppo_num_epochs": 10,
  "ppo_num_minibatch": 5,
  "ppo_use_huberloss": false,
  "ppo_use_clipped_value_loss": false,
  "ppo_clip_param": 0.2,
  "lr_policy": 0.0005,
  "lr_vae": 0.0005,
  "num_processes": 21,
  "policy_num_steps": 5000,
  "policy_eps": 1e-08,
  "policy_init_std": 1.0,
  "policy_fix_std": false,
  "policy_value_loss_coef": 1.0,
  "policy_entropy_coef": 5e-06,
  "policy_gamma": 0.99,
  "policy_use_gae": true,
  "policy_tau": 0.95,
  "use_proper_time_limits": false,
  "policy_max_grad_norm": 0.5,
  "encoder_max_grad_norm": 0.5,
  "decoder_max_grad_norm": null,
  "size_vae_buffer": 0,
  "precollect_len": 0,
  "vae_buffer_add_thresh": 1,
  "vae_batch_num_trajs": 10,
  "tbptt_stepsize": null,
  "vae_subsample_elbos": 50,
  "vae_subsample_decodes": null,
  "num_vae_updates": 1,
  "pretrain_len": 0,
  "kl_weight": 0.1,
  "split_batches_by_task": false,
  "split_batches_by_elbo": false,
  "action_embedding_size": 32,
  "state_embedding_size": 64,
  "reward_embedding_size": 32,
  "encoder_layers_before_gru": [],
  "encoder_gru_hidden_size": 128,
  "encoder_layers_after_gru": [],
  "decode_reward": false,
  "rew_loss_coeff": 1.0,
  "input_prev_state": true,
  "input_action": true,
  "reward_decoder_layers": [
    64,
    32
  ],
  "multihead_for_reward": false,
  "rew_pred_type": "deterministic",
  "decode_state": false,
  "state_loss_coeff": 1.0,
  "state_decoder_layers": [
    64,
    32
  ],
  "state_pred_type": "deterministic",
  "decode_task": false,
  "task_loss_coeff": 1.0,
  "task_decoder_layers": [
    64,
    32
  ],
  "task_pred_type": "task_id",
  "sample_embeddings": false,
  "vae_loss_coeff": 1.0,
  "disable_metalearner": false,
  "single_task_mode": false,
  "log_interval": 25,
  "save_interval": 10,
  "save_intermediate_models": false,
  "eval_interval": 10,
  "vis_interval": 500,
  "results_log_dir": null,
  "seed": 73,
  "deterministic_execution": false,
  "load_model_from_checkpoint": null,
  "action_space": null,
  "device": "cuda"
}