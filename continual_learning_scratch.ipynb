{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scratch development for continual learning loop\n",
    "\n",
    "What I want to do:\n",
    "- There is a continual learning env that lets an agent learn on a stream of tasks\n",
    "- At specified intervals, we can evaluate the continual learner on _every_ task in the training set\n",
    "\n",
    "Things to consider:\n",
    "- can I use the ML10 environments in this setting? goals are obscured, what does that mean?\n",
    "- how many steps per env do I want? I think CW uses 1 million? check this, also, with PPO is this enough? (CW uses SAC)\n",
    "- randomisation of task goals - CW seems to have randomisation settings for the benchmark. MT and ML have randomised environments. How should we handle these tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other thoughts\n",
    "Next step is to integrate the continual environment and evaluation loop into a training loop. We want to use the PPO algorithm provided (or something similar), but provide it with arbitrary policy / value networks (i.e. our own).\n",
    "\n",
    "Testing learning in this way might require setting up some command line 'args' stuff - might be easier to match it with PPO\n",
    "But is this the simplest testing method?\n",
    "\n",
    "Should look at policy storage - how can I use that?\n",
    "\n",
    "Also - continue to look at how to get continual environments to work. Continual world has randomization handlers, success counters etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('./algorithms/')\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RL2 trained policy for example\n",
    "RUN_FOLDER = './logs/logs_ML10-v2/rl2_73__25:10_21:13:08'\n",
    "policy_net = torch.load(RUN_FOLDER + '/models/policy.pt')\n",
    "encoder_net = torch.load(RUN_FOLDER + '/models/encoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import metaworld\n",
    "import random\n",
    "\n",
    "class ML10Env(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        # initialise blank env\n",
    "        \n",
    "        self.benchmark = metaworld.ML10()\n",
    "        # set a random task from the benchmark\n",
    "        self.set_task()\n",
    "\n",
    "        # requires self.set_task()\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "        # metaworld max steps - hardcoded\n",
    "        self._max_episode_steps = 500\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        info['task'] = self.task\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        obs, _ = self.env.reset()\n",
    "        return obs\n",
    "    \n",
    "    \n",
    "    def get_task(self):\n",
    "        return self.benchmark.train_classes\n",
    "    \n",
    "    ## reset_task is automatically created in make_env using set_task\n",
    "    def set_task(self, task = None):\n",
    "        if task is None:\n",
    "            env_name, env_cls = random.choice(list(self.benchmark.train_classes.items()))\n",
    "            self.env = env_cls()\n",
    "            task = random.choice([task for task in self.benchmark.train_tasks if task.env_name==env_name])\n",
    "\n",
    "        self.task = task\n",
    "        self.env.set_task(self.task)\n",
    "\n",
    "    # duplicated for varibad temporarily\n",
    "    def reset_task(self, task = None):\n",
    "        if task is None:\n",
    "            env_name, env_cls = random.choice(list(self.benchmark.train_classes.items()))\n",
    "            self.env = env_cls()\n",
    "            task = random.choice([task for task in self.benchmark.train_tasks if task.env_name==env_name])\n",
    "\n",
    "        self.task = task\n",
    "        self.env.set_task(self.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import metaworld\n",
    "import random\n",
    "\n",
    "## I want to get soccer-v2 env from ML45\n",
    "\n",
    "ML45 = metaworld.ML45()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_soccer_v2.SawyerSoccerEnvV2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use get_subtasks to get the \n",
    "ML45.train_classes['soccer-v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see how the metaworld benchmark classes are created - can you create an arbitrary benchmark comprised of classes and tasks?\n",
    "# class customBenchmark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from metaworld.envs.mujoco.env_dict import ALL_V2_ENVIRONMENTS\n",
    "from metaworld.envs.mujoco.sawyer_xyz.v2 import (\n",
    "    SawyerBasketballEnvV2,\n",
    "    SawyerBinPickingEnvV2,\n",
    "    SawyerBoxCloseEnvV2,\n",
    "    SawyerButtonPressEnvV2,\n",
    "    SawyerButtonPressTopdownEnvV2,\n",
    "    SawyerButtonPressTopdownWallEnvV2,\n",
    "    SawyerButtonPressWallEnvV2,\n",
    "    SawyerCoffeeButtonEnvV2,\n",
    "    SawyerCoffeePullEnvV2,\n",
    "    SawyerCoffeePushEnvV2,\n",
    "    SawyerDialTurnEnvV2,\n",
    "    SawyerDoorCloseEnvV2,\n",
    "    SawyerDoorEnvV2,\n",
    "    SawyerDoorLockEnvV2,\n",
    "    SawyerDoorUnlockEnvV2,\n",
    "    SawyerDrawerCloseEnvV2,\n",
    "    SawyerDrawerOpenEnvV2,\n",
    "    SawyerFaucetCloseEnvV2,\n",
    "    SawyerFaucetOpenEnvV2,\n",
    "    SawyerHammerEnvV2,\n",
    "    SawyerHandInsertEnvV2,\n",
    "    SawyerHandlePressEnvV2,\n",
    "    SawyerHandlePressSideEnvV2,\n",
    "    SawyerHandlePullEnvV2,\n",
    "    SawyerHandlePullSideEnvV2,\n",
    "    SawyerLeverPullEnvV2,\n",
    "    SawyerNutAssemblyEnvV2,\n",
    "    SawyerNutDisassembleEnvV2,\n",
    "    SawyerPegInsertionSideEnvV2,\n",
    "    SawyerPegUnplugSideEnvV2,\n",
    "    SawyerPickOutOfHoleEnvV2,\n",
    "    SawyerPickPlaceEnvV2,\n",
    "    SawyerPickPlaceWallEnvV2,\n",
    "    SawyerPlateSlideBackEnvV2,\n",
    "    SawyerPlateSlideBackSideEnvV2,\n",
    "    SawyerPlateSlideEnvV2,\n",
    "    SawyerPlateSlideSideEnvV2,\n",
    "    SawyerPushBackEnvV2,\n",
    "    SawyerPushEnvV2,\n",
    "    SawyerPushWallEnvV2,\n",
    "    SawyerReachEnvV2,\n",
    "    SawyerReachWallEnvV2,\n",
    "    SawyerShelfPlaceEnvV2,\n",
    "    SawyerSoccerEnvV2,\n",
    "    SawyerStickPullEnvV2,\n",
    "    SawyerStickPushEnvV2,\n",
    "    SawyerSweepEnvV2,\n",
    "    SawyerSweepIntoGoalEnvV2,\n",
    "    SawyerWindowCloseEnvV2,\n",
    "    SawyerWindowOpenEnvV2,\n",
    ")\n",
    "\n",
    "CustomML10_V2 = OrderedDict(\n",
    "    (\n",
    "        (\n",
    "            \"train\",\n",
    "            OrderedDict(\n",
    "                (\n",
    "                        (\"reach-v2\", SawyerReachEnvV2),\n",
    "                        # (\"push-v2\", SawyerPushEnvV2),\n",
    "                        (\"soccer-v2\", SawyerSoccerEnvV2),\n",
    "                        (\"pick-place-v2\", SawyerPickPlaceEnvV2),\n",
    "                        (\"door-open-v2\", SawyerDoorEnvV2),\n",
    "                        (\"drawer-close-v2\", SawyerDrawerCloseEnvV2),\n",
    "                        (\"button-press-topdown-v2\", SawyerButtonPressTopdownEnvV2),\n",
    "                        (\"peg-insert-side-v2\", SawyerPegInsertionSideEnvV2),\n",
    "                        (\"window-open-v2\", SawyerWindowOpenEnvV2),\n",
    "                        (\"sweep-v2\", SawyerSweepEnvV2),\n",
    "                        (\"basketball-v2\", SawyerBasketballEnvV2)\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "    (\n",
    "        \"test\",\n",
    "         OrderedDict(\n",
    "            (\n",
    "            (\"drawer-open-v2\", SawyerDrawerOpenEnvV2),\n",
    "            (\"door-close-v2\", SawyerDoorCloseEnvV2),\n",
    "            (\"shelf-place-v2\", SawyerShelfPlaceEnvV2),\n",
    "            (\"sweep-into-v2\", SawyerSweepIntoGoalEnvV2),\n",
    "            (\"lever-pull-v2\",SawyerLeverPullEnvV2)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    ")\n",
    "\n",
    "custom_ml10_train_args_kwargs = {\n",
    "    key:dict(\n",
    "        args = [],\n",
    "        kwargs = {\n",
    "            'task_id': list(ALL_V2_ENVIRONMENTS.keys()).index(key)\n",
    "        }\n",
    "    )\n",
    "    for key, _ in CustomML10_V2[\"train\"].items()\n",
    "}\n",
    "\n",
    "custom_ml10_test_args_kwargs = {\n",
    "    key:dict(\n",
    "        args = [],\n",
    "        kwargs = {\n",
    "            'task_id': list(ALL_V2_ENVIRONMENTS.keys()).index(key)\n",
    "        }\n",
    "    )\n",
    "    for key, _ in CustomML10_V2[\"test\"].items()\n",
    "}\n",
    "\n",
    "CUSTOMML10_ARGS_KWARGS = dict(\n",
    "    train = custom_ml10_train_args_kwargs,\n",
    "    test = custom_ml10_test_args_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaworld import Benchmark, _make_tasks, _ML_OVERRIDE\n",
    "\n",
    "class CustomML10(Benchmark):\n",
    "    def __init__(self, seed=None):\n",
    "        super().__init__()\n",
    "        self._train_classes = CustomML10_V2[\"train\"]\n",
    "        self._test_classes = CustomML10_V2[\"test\"]\n",
    "        train_kwargs = custom_ml10_train_args_kwargs\n",
    "\n",
    "        test_kwargs = custom_ml10_test_args_kwargs\n",
    "        self._train_tasks = _make_tasks(\n",
    "            self._train_classes, train_kwargs, _ML_OVERRIDE, seed=seed\n",
    "        )\n",
    "\n",
    "        self._test_tasks = _make_tasks(\n",
    "            self._test_classes, test_kwargs, _ML_OVERRIDE, seed=seed\n",
    "        )\n",
    "\n",
    "customML10_benchmark = CustomML10(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('reach-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_reach_v2.SawyerReachEnvV2),\n",
       "             ('soccer-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_soccer_v2.SawyerSoccerEnvV2),\n",
       "             ('pick-place-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_pick_place_v2.SawyerPickPlaceEnvV2),\n",
       "             ('door-open-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_door_v2.SawyerDoorEnvV2),\n",
       "             ('drawer-close-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_drawer_close_v2.SawyerDrawerCloseEnvV2),\n",
       "             ('button-press-topdown-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_button_press_topdown_v2.SawyerButtonPressTopdownEnvV2),\n",
       "             ('peg-insert-side-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_peg_insertion_side_v2.SawyerPegInsertionSideEnvV2),\n",
       "             ('window-open-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_window_open_v2.SawyerWindowOpenEnvV2),\n",
       "             ('sweep-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_sweep_v2.SawyerSweepEnvV2),\n",
       "             ('basketball-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_basketball_v2.SawyerBasketballEnvV2)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customML10_benchmark.train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('reach-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_reach_v2.SawyerReachEnvV2),\n",
       "             ('soccer-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_soccer_v2.SawyerSoccerEnvV2),\n",
       "             ('pick-place-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_pick_place_v2.SawyerPickPlaceEnvV2),\n",
       "             ('door-open-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_door_v2.SawyerDoorEnvV2),\n",
       "             ('drawer-close-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_drawer_close_v2.SawyerDrawerCloseEnvV2),\n",
       "             ('button-press-topdown-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_button_press_topdown_v2.SawyerButtonPressTopdownEnvV2),\n",
       "             ('peg-insert-side-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_peg_insertion_side_v2.SawyerPegInsertionSideEnvV2),\n",
       "             ('window-open-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_window_open_v2.SawyerWindowOpenEnvV2),\n",
       "             ('sweep-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_sweep_v2.SawyerSweepEnvV2),\n",
       "             ('basketball-v2',\n",
       "              metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_basketball_v2.SawyerBasketballEnvV2)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomML10_V2['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, policy, encoder):\n",
    "        super().__init__()\n",
    "        self.policy = policy\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    def get_actor_params(self):\n",
    "        return self.policy.get_actor_params()\n",
    "\n",
    "    def get_critic_params(self):\n",
    "        return self.policy.get_critic_params()\n",
    "\n",
    "    def forward_actor(self, inputs):\n",
    "        return self.policy.forward_actor(inputs)\n",
    "\n",
    "    def forward_critic(self, inputs):\n",
    "        return self.policy.forward_critic(inputs)\n",
    "    \n",
    "    ## TODO: what to do about 'sample'? check what this arg is?\n",
    "    # def forward(self, actions, states, rewards, hidden_state, return_prior=False, sample=True, detach_every=None):\n",
    "    #     # really want this to take the inputs for the encoder and then output the outputs of the policy\n",
    "    #     # we only want to get the prior when there are no previous rewards, actions or hidden states\n",
    "    #     # should only occur at the very start of the continual learning process\n",
    "    #     if hidden_state is None:\n",
    "    #         # print('Hidden state is None!!:', hidden_state)\n",
    "    #         _, latent_mean, latent_logvar, hidden_state = self.encoder.prior(states.shape[1]) # check that this gets the batch size?\n",
    "    #     else:\n",
    "    #         _, latent_mean, latent_logvar, hidden_state = self.encoder(actions, states, rewards, hidden_state, return_prior, sample, detach_every)\n",
    "        \n",
    "    #     latent_mean = F.relu(latent_mean)\n",
    "    #     latent_logvar = F.relu(latent_logvar)\n",
    "    #     latent = torch.cat((latent_mean, latent_logvar), dim=-1).reshape(1, -1)\n",
    "    #     # none for belief and task\n",
    "    #     return self.policy(states, latent, None, None), hidden_state, latent\n",
    "    \n",
    "    # def prior(self, num_processes):\n",
    "    #     return self.encoder.prior(num_processes)\n",
    "\n",
    "\n",
    "    def act(self, state, latent, belief=None, task=None, deterministic = False):\n",
    "        # \"\"\"\n",
    "        # Returns the (raw) actions and their value.\n",
    "        # \"\"\"\n",
    "        # policy_out, hidden_state, latent = self.forward(actions, states, rewards, hidden_state, sample=True)\n",
    "        # value, actor_features = policy_out\n",
    "        # dist = self.policy.dist(actor_features)\n",
    "        # if deterministic:\n",
    "        #     if isinstance(dist, FixedCategorical):\n",
    "        #         action = dist.mode()\n",
    "        #     else:\n",
    "        #         ## TODO: should the 'mean' have brackets or not?\n",
    "        #         action = dist.mean()\n",
    "        # else:\n",
    "        #     action = dist.sample()\n",
    "\n",
    "        return self.policy.act(state, latent, belief, task, deterministic)\n",
    "\n",
    "    def get_value(self, state, latent, belief=None, task=None):\n",
    "        value, _ = self.policy.forward(state, latent, belief, task)\n",
    "        return value\n",
    "\n",
    "    def evaluate_actions(self, state, latent, belief, task, action):\n",
    "        \"\"\"Call policy eval, set task, belief to None\"\"\"\n",
    "        return self.policy.evaluate_actions(state, latent, belief, task, action)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. get prior at start for base latent\n",
    "# (does this reset the hidden state? I think so)\n",
    "#2. feed policy observation + latent -> gets action, obs, reward, done\n",
    "#3. feed encoder action, obs, reward, done and hidden state to get next action\n",
    "import metaworld\n",
    "import random\n",
    "\n",
    "ml10 = metaworld.ML10() # Construct the benchmark, sampling tasks\n",
    "\n",
    "training_envs = []\n",
    "for name, env_cls in ml10.test_classes.items():\n",
    "  env = env_cls()\n",
    "  task = random.choice([task for task in ml10.test_tasks\n",
    "                        if task.env_name == name])\n",
    "  env.set_task(task)\n",
    "  training_envs.append(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499: done!\n"
     ]
    }
   ],
   "source": [
    "from algorithms.custom_storage import CustomOnlineStorage\n",
    "from algorithms.custom_ppo import CustomPPO, RecurrentPPO\n",
    "import utils.custom_helpers as utl\n",
    "\n",
    "window_size =64\n",
    "# combined network with encoder + policy\n",
    "ac = ActorCritic(policy_net, encoder_net)\n",
    "agent = RecurrentPPO(\n",
    "    actor_critic=ac,\n",
    "    value_loss_coef = 1,\n",
    "    entropy_coef = 0.001,\n",
    "    policy_optimiser='adam',\n",
    "    policy_anneal_lr=False,\n",
    "    train_steps = 2,\n",
    "    lr = 0.001,\n",
    "    eps=1.0e-8,\n",
    "    clip_param = 0.2,\n",
    "    ppo_epoch = 3,\n",
    "    use_huber_loss = True,\n",
    "    use_clipped_value_loss=True,\n",
    "    context_window=window_size\n",
    ")\n",
    "env = training_envs[0]\n",
    "\n",
    "storage = CustomOnlineStorage(\n",
    "    500, 1, env.observation_space.shape[0]+1, 0, 0,\n",
    "    env.action_space, ac.encoder.hidden_size, ac.encoder.latent_dim, False)\n",
    "\n",
    "# get it going\n",
    "NUM_EP = 1\n",
    "# reward = action = hidden_state = None\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_steps = 0\n",
    "\n",
    "for i in range(NUM_EP):\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    # get the prior\n",
    "    with torch.no_grad():\n",
    "        _, latent_mean, latent_logvar, hidden_state = agent.actor_critic.encoder.prior(1)\n",
    "\n",
    "    # add this initial hidden state to the policy storage\n",
    "    assert len(storage.latent) == 0  # make sure we emptied buffers\n",
    "    storage.hidden_states[0].copy_(hidden_state.squeeze(1))\n",
    "    latent = torch.cat((latent_mean.clone(), latent_logvar.clone()), dim=-1).reshape(1, -1)\n",
    "    storage.latent.append(latent)\n",
    "\n",
    "    ## TODO: put this into the environment wrapper\n",
    "    obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1)).to(device)[None,:,:]\n",
    "\n",
    "    step = 0\n",
    "    while not done:\n",
    "        value, act = agent.act(obs.float(), latent, None, None)\n",
    "        # print(step, obs.size(), latent.size(), act.size())\n",
    "        action = act.cpu().detach().numpy()[0]\n",
    "        # print(action.shape)\n",
    "        # print(hidden_state)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        ## TODO: Tidy all of this up. Use environment wrappers to convert outputs to torch formats\n",
    "        obs = next_obs\n",
    "        next_state = torch.from_numpy(np.append(next_obs, 0).reshape(1, -1)).to(device)\n",
    "        reward = torch.from_numpy(np.array(reward).reshape(1, -1)).float().to(device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        ## don't worry about this for now\n",
    "        episode_reward += reward\n",
    "        episode_steps += 1\n",
    "\n",
    "        # create mask for episode ends\n",
    "        masks_done = torch.FloatTensor([[0.0] if done else [1.0] ]).to(device)\n",
    "        # bad_mask is true if episode ended because time limit was reached\n",
    "        # don't care for metaworld\n",
    "        bad_masks = torch.FloatTensor([[0.0]]).to(device)\n",
    "\n",
    "        # TODO: convert reset_hidden to actor critic level\n",
    "        if done:\n",
    "            print(f'{step}: done!')\n",
    "            hidden_state = agent.actor_critic.encoder.reset_hidden(hidden_state, masks_done)\n",
    "\n",
    "                # update encoding\n",
    "        # TODO: make this a recurrent update\n",
    "        first_idx = np.max([0, step-window_size])\n",
    "        last_idx = step if step < window_size else first_idx + window_size # -1\n",
    "        # print(first_idx, last_idx, f\"Step + 1: {step+1}\")\n",
    "        # need tensor of TXBXD - get from storage +  current action\n",
    "        # print(storage.actions[first_idx:last_idx].size(),storage.actions[first_idx:last_idx])\n",
    "        batch_act = utl.build_sequence_from_storage(storage.actions[first_idx:last_idx], act[None, :], window_size - 1)#torch.cat((storage.actions[first_idx:last_idx], act[None, :]), dim=0)\n",
    "        batch_next_state = utl.build_sequence_from_storage(storage.next_state[first_idx:last_idx], next_state[None, :], window_size - 1)#torch.cat((storage.next_state[first_idx:last_idx], next_state[None, :]), dim = 0)\n",
    "        batch_reward = utl.build_sequence_from_storage(storage.rewards_raw[first_idx:last_idx], reward[None, :], window_size - 1)#torch.cat((storage.rewards_raw[first_idx:last_idx], reward[None, :]), dim = 0)\n",
    "        hidden_state = None\n",
    "        # print(batch_act.size(), batch_next_state.size(), batch_reward.size())\n",
    "        if step == 0:\n",
    "            first_act = batch_act\n",
    "        if step == 1:\n",
    "            second_act = batch_act\n",
    "\n",
    "        # TODO: convert this to actor critic level\n",
    "        _, latent_mean, latent_logvar, hidden_state = agent.actor_critic.encoder(\n",
    "            batch_act, \n",
    "            batch_next_state.float(), \n",
    "            batch_reward, \n",
    "            hidden_state, \n",
    "            return_prior = False, \n",
    "            detach_every=window_size)\n",
    "        latent = torch.cat((latent_mean.clone(), latent_logvar.clone()), dim = -1)[-1]#.reshape(1, -1)\n",
    "        hidden_state = hidden_state[-1]\n",
    "\n",
    "        storage.next_state[step] = next_state.clone()        \n",
    "\n",
    "        storage.insert(\n",
    "            state=next_state,\n",
    "            belief=None,\n",
    "            task=None,\n",
    "            actions=act,\n",
    "            rewards_raw=reward,\n",
    "            rewards_normalised=reward,#rew_normalised,\n",
    "            value_preds=value,\n",
    "            masks=masks_done,\n",
    "            bad_masks=bad_masks,\n",
    "            done=torch.from_numpy(np.array(done, dtype=float)),\n",
    "            hidden_states = hidden_state,#.squeeze(1),\n",
    "            latent = latent#.unsqueeze(1),\n",
    "        )\n",
    "        ## TODO: put this into the environment wrapper\n",
    "        obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1)).to(device)[None,:,:]\n",
    "        # reward = reward.to(device)\n",
    "        # action = torch.from_numpy(action)[None, None,:].to(device)\n",
    "\n",
    "        ## update step\n",
    "        step += 1\n",
    "        # if step ==1:\n",
    "        #     break\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9081909815470377,\n",
       " 0.010871242421368757,\n",
       " 4.677809079488118,\n",
       " 1.914384412765503)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.update(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.5509e-03, -6.2940e-03, -2.0294e-03,  ..., -2.2594e-03,\n",
      "          1.5364e-03,  1.1307e-02],\n",
      "        [ 1.0299e-03, -6.8960e-03, -6.5105e-04,  ...,  2.1867e-03,\n",
      "          1.8574e-03,  2.9854e-04],\n",
      "        [-3.4827e-03,  3.2738e-03, -2.3102e-03,  ..., -2.4406e-03,\n",
      "         -4.1596e-03, -1.0923e-02],\n",
      "        ...,\n",
      "        [-5.9851e-04,  1.7963e-03, -8.5353e-04,  ...,  1.6768e-03,\n",
      "          4.7483e-05, -1.3435e-03],\n",
      "        [-3.5381e-03, -2.4882e-03, -5.9807e-04,  ...,  9.0474e-04,\n",
      "          1.4992e-03,  1.0845e-02],\n",
      "        [-3.1716e-03, -9.1322e-04,  2.9080e-03,  ...,  3.8809e-03,\n",
      "          3.4551e-03,  9.1250e-03]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([-1.9294e-03, -4.1245e-03,  4.5184e-03, -3.3930e-03,  8.1090e-04,\n",
      "         4.9451e-03, -1.6772e-03,  2.5830e-04, -2.0754e-03,  1.5776e-03,\n",
      "         5.9071e-03, -5.1281e-03, -5.7853e-04, -1.6522e-03, -5.3458e-03,\n",
      "        -3.9014e-03, -2.9146e-04,  5.2802e-03,  4.9478e-03, -4.6042e-03,\n",
      "         2.0704e-04, -3.0331e-03, -3.9031e-04, -7.1270e-03, -2.3581e-03,\n",
      "         4.4931e-03,  5.4243e-04, -3.0667e-03,  3.6811e-03, -6.7491e-03,\n",
      "        -5.8647e-04,  6.3422e-03, -6.2425e-03,  2.4120e-03, -2.1175e-03,\n",
      "        -4.8209e-03, -6.2870e-03, -3.1562e-03, -1.1134e-03, -4.6949e-03,\n",
      "         8.7086e-04, -1.4724e-03, -4.1606e-03,  3.8547e-03, -2.2283e-03,\n",
      "         3.1505e-03,  1.1360e-03,  3.7975e-03, -5.8062e-03,  3.0025e-03,\n",
      "         5.0237e-03, -3.7471e-03,  3.0227e-03, -4.7443e-03,  2.8884e-03,\n",
      "         6.0551e-03,  1.1798e-03,  6.3952e-03,  1.6300e-03, -1.6544e-03,\n",
      "        -3.1874e-03, -6.6215e-04,  1.0882e-03, -6.0445e-03,  1.4627e-03,\n",
      "        -1.6455e-03,  4.1386e-03,  2.1298e-03,  1.5180e-04, -1.9722e-03,\n",
      "        -5.7112e-03, -3.4430e-04, -1.7886e-03, -1.9132e-03,  3.6478e-03,\n",
      "         3.7491e-03, -1.4351e-03,  2.6871e-03, -6.8561e-03,  1.5970e-03,\n",
      "        -3.2441e-03,  1.1233e-03, -3.1556e-03, -5.6144e-03, -5.9014e-03,\n",
      "         1.7851e-03,  4.3959e-03, -1.3706e-04, -5.9463e-03, -2.0083e-03,\n",
      "         1.7553e-03,  5.4306e-03, -9.0701e-04,  4.8293e-03,  1.1557e-04,\n",
      "        -3.7738e-03, -3.1762e-03,  5.6973e-03,  2.2215e-03, -6.2430e-03,\n",
      "        -2.0159e-03, -2.8015e-03, -1.6603e-03, -6.2982e-03, -6.4068e-04,\n",
      "        -2.9141e-03,  2.4686e-04,  1.2822e-03, -6.0244e-03, -5.7867e-03,\n",
      "         1.0401e-05, -3.0473e-03, -4.6147e-04,  1.5783e-03,  1.2319e-03,\n",
      "        -9.3058e-04, -2.8588e-03, -3.5492e-03,  3.8966e-03, -7.3111e-03,\n",
      "        -5.6678e-03, -2.2621e-03,  5.1738e-03,  6.6750e-03, -1.3859e-03,\n",
      "        -3.8040e-03, -4.9296e-03, -7.0831e-03], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[ 0.0049, -0.0049, -0.0049,  ..., -0.0048, -0.0049, -0.0048],\n",
      "        [-0.0049,  0.0049,  0.0049,  ...,  0.0048,  0.0048,  0.0048],\n",
      "        [-0.0049,  0.0049,  0.0049,  ...,  0.0049,  0.0049,  0.0049],\n",
      "        ...,\n",
      "        [-0.0049,  0.0052,  0.0050,  ...,  0.0046,  0.0047,  0.0044],\n",
      "        [ 0.0068,  0.0073,  0.0054,  ...,  0.0040,  0.0044, -0.0010],\n",
      "        [-0.0049,  0.0049,  0.0049,  ...,  0.0048,  0.0049,  0.0048]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([ 4.6750e-03, -4.5918e-03, -4.7310e-03,  3.8578e-03,  4.6534e-03,\n",
      "         4.7059e-03, -4.4303e-03,  4.7306e-03,  4.0090e-03, -2.9601e-03,\n",
      "        -4.7213e-03, -4.7761e-03, -2.8317e-03,  3.5231e-03,  4.1493e-03,\n",
      "        -4.6867e-03, -4.5568e-03, -2.6376e-03, -2.0985e-03, -4.6373e-03,\n",
      "        -4.0217e-03, -4.4400e-03, -4.7025e-03,  1.7184e-03, -4.7734e-03,\n",
      "        -4.8366e-03, -1.5413e-03,  4.3357e-03, -4.5402e-03, -4.7052e-03,\n",
      "         3.1243e-03,  4.7172e-03,  5.5792e-04, -4.7026e-03, -4.7206e-03,\n",
      "         4.6993e-03, -4.7620e-03,  3.3068e-03,  4.7269e-03, -4.3812e-03,\n",
      "         2.6749e-03, -4.6628e-03,  4.6764e-03, -3.5106e-03,  1.7635e-04,\n",
      "        -6.0111e-03, -2.2632e-03,  4.7208e-03, -3.9196e-03,  4.6582e-03,\n",
      "        -2.9756e-03, -2.5551e-03,  9.4175e-04, -4.6563e-03, -4.3627e-03,\n",
      "        -1.4387e-03,  4.7280e-03, -4.1966e-03,  4.7432e-03,  4.6296e-03,\n",
      "        -4.2034e-03, -4.5034e-03, -4.4600e-03,  4.7610e-03, -4.7019e-03,\n",
      "        -4.6388e-03,  1.1334e-03, -4.7261e-03,  4.2252e-03,  4.6265e-03,\n",
      "        -2.8612e-03,  4.3787e-03, -4.6293e-03, -8.0098e-04, -4.6005e-03,\n",
      "         3.7202e-03, -4.4440e-03,  3.4931e-03,  4.7375e-03, -4.6087e-03,\n",
      "         4.1511e-03, -1.1463e-03,  4.9614e-03,  4.7561e-03,  4.6463e-03,\n",
      "         5.2625e-03, -3.8070e-03,  4.7917e-03,  4.7804e-03, -4.7850e-03,\n",
      "         4.5016e-03,  1.2250e-03, -4.6177e-03,  2.9952e-03,  4.7582e-03,\n",
      "        -4.5713e-03, -3.8159e-03, -4.7270e-03, -4.0305e-03,  4.7042e-03,\n",
      "         4.5141e-03,  4.5393e-03,  4.3439e-03,  4.6166e-03, -9.1880e-05,\n",
      "         3.1890e-03, -4.3215e-03, -3.3920e-03, -4.5377e-03,  3.9458e-03,\n",
      "        -2.3018e-03,  2.3447e-03,  4.7696e-03, -4.2401e-03,  3.2883e-03,\n",
      "        -3.8003e-03,  4.7455e-03, -4.2915e-03,  3.9188e-03, -4.6760e-03,\n",
      "        -3.5216e-03,  1.5125e-03, -3.9052e-03, -5.2001e-03,  3.4090e-03,\n",
      "        -3.4417e-03, -1.4923e-03, -4.6376e-03], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[ 0.0048,  0.0049, -0.0048, -0.0049, -0.0049, -0.0049,  0.0049, -0.0049,\n",
      "         -0.0049,  0.0049, -0.0049,  0.0049,  0.0049, -0.0049, -0.0049,  0.0049,\n",
      "         -0.0048,  0.0049,  0.0049, -0.0049,  0.0049,  0.0049,  0.0049, -0.0049,\n",
      "          0.0049,  0.0049,  0.0049,  0.0049,  0.0049,  0.0049, -0.0049, -0.0049,\n",
      "         -0.0049,  0.0049,  0.0049,  0.0049,  0.0049, -0.0049, -0.0049,  0.0049,\n",
      "         -0.0049,  0.0049,  0.0049,  0.0049, -0.0049,  0.0049,  0.0049,  0.0049,\n",
      "          0.0049, -0.0049,  0.0049,  0.0049, -0.0049,  0.0049,  0.0049,  0.0049,\n",
      "         -0.0049,  0.0049, -0.0049, -0.0049,  0.0049,  0.0049,  0.0049, -0.0049,\n",
      "          0.0049,  0.0049, -0.0049,  0.0049, -0.0049,  0.0049,  0.0049, -0.0049,\n",
      "          0.0049,  0.0049,  0.0049, -0.0049,  0.0049, -0.0049, -0.0049,  0.0049,\n",
      "         -0.0049,  0.0049, -0.0049, -0.0047,  0.0049, -0.0049,  0.0049, -0.0055,\n",
      "         -0.0061,  0.0049, -0.0049, -0.0049,  0.0049, -0.0049, -0.0052,  0.0049,\n",
      "          0.0049, -0.0042,  0.0049,  0.0048, -0.0049, -0.0049, -0.0049, -0.0049,\n",
      "         -0.0049, -0.0049,  0.0049,  0.0049, -0.0049, -0.0049,  0.0049, -0.0049,\n",
      "         -0.0049,  0.0049, -0.0049,  0.0049, -0.0049,  0.0049, -0.0049, -0.0049,\n",
      "          0.0049, -0.0049,  0.0049,  0.0049,  0.0049,  0.0049,  0.0049,  0.0049]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([-0.0048], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([-0.0078, -0.0053,  0.0004, -0.0100], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[ 5.1589e-04,  1.7291e-04, -1.9500e-04,  2.1469e-03,  2.1479e-03,\n",
      "          2.0147e-03, -1.8471e-03,  2.2882e-03, -4.8388e-03, -2.9101e-03,\n",
      "          1.2250e-03, -2.1661e-03, -1.2423e-03, -3.2604e-03,  4.1310e-04,\n",
      "          1.3740e-03, -2.0964e-04, -3.3984e-04,  7.6030e-04,  1.1709e-03,\n",
      "          4.1379e-03,  3.2201e-04, -4.0304e-04, -5.4092e-04,  2.2180e-04,\n",
      "          1.1171e-03,  2.0720e-03,  1.9942e-03, -9.2062e-04,  1.5006e-03,\n",
      "          1.2934e-03,  1.1760e-03, -2.1108e-03, -4.4041e-04, -5.0575e-05,\n",
      "          1.6168e-04, -1.5854e-03,  1.3994e-03, -1.6459e-03, -1.5433e-03,\n",
      "          4.9935e-04, -1.6877e-03,  1.7917e-03, -2.7164e-03, -1.9527e-03,\n",
      "         -1.5055e-04, -1.0088e-03,  1.5277e-03,  1.0644e-03,  8.2409e-04,\n",
      "          3.4767e-04, -3.1199e-03,  1.7512e-04,  9.4920e-04, -4.2616e-04,\n",
      "         -1.1219e-04, -3.4702e-03, -6.3334e-04,  1.7336e-04,  1.0539e-03,\n",
      "          3.7890e-03,  1.1941e-03, -1.2186e-03, -1.1515e-03, -2.6184e-03,\n",
      "          3.4959e-03, -3.9420e-03,  1.1913e-04, -5.0826e-04,  5.0191e-04,\n",
      "         -1.6136e-04, -4.3086e-04,  7.3306e-04,  6.5337e-04, -2.1300e-03,\n",
      "          4.9969e-03,  5.9008e-04, -3.5098e-03, -1.8499e-03, -7.6707e-04,\n",
      "         -3.0298e-04,  1.7963e-04,  4.9287e-03,  5.8228e-04, -2.9249e-04,\n",
      "          1.3244e-03,  1.5368e-04,  3.0191e-03, -6.2975e-04,  2.2824e-03,\n",
      "         -4.9455e-03, -1.4445e-03,  3.0883e-05,  2.4087e-03, -2.4116e-03,\n",
      "         -3.9753e-05, -1.1675e-03, -1.3997e-04, -1.5566e-03, -2.0845e-03,\n",
      "          4.7143e-03, -7.8214e-04,  5.3186e-04, -1.9285e-03,  7.2835e-04,\n",
      "         -1.8274e-03,  1.9729e-03,  4.2030e-04, -1.2865e-03, -8.0674e-04,\n",
      "         -2.1756e-05,  6.5301e-04,  2.1599e-05,  9.4530e-04, -4.7717e-04,\n",
      "          1.0505e-03,  1.7248e-03,  2.7311e-04,  5.8628e-04, -2.0645e-03,\n",
      "          7.7722e-04,  2.2293e-03,  1.1940e-03, -2.0294e-06, -7.6473e-05,\n",
      "         -4.2284e-03,  1.2662e-03, -2.7613e-03],\n",
      "        [ 1.1693e-04, -1.3304e-03,  1.4674e-04,  9.1988e-04, -2.5191e-03,\n",
      "         -5.7577e-04, -8.9185e-04, -2.8227e-03, -5.8253e-03, -1.9997e-04,\n",
      "          1.1264e-03,  4.0391e-04, -5.6969e-04, -1.5477e-03, -1.5931e-03,\n",
      "         -1.2469e-05,  8.9630e-05,  2.2600e-04,  8.1670e-05, -1.2585e-03,\n",
      "          2.1628e-03,  6.5704e-04,  4.3198e-04, -1.2807e-04,  9.3918e-04,\n",
      "          1.3016e-03, -1.1462e-03, -1.3396e-03,  1.7164e-03,  9.3056e-04,\n",
      "         -6.8314e-04, -3.7684e-03,  1.2281e-03,  4.5741e-04,  4.4817e-04,\n",
      "          1.3968e-03, -5.3751e-04,  2.6608e-04, -2.3603e-03, -1.3902e-03,\n",
      "         -4.4041e-04,  1.6187e-03, -6.9343e-04, -2.9802e-03, -9.6914e-04,\n",
      "         -9.8121e-04,  1.0462e-03, -5.2686e-04,  1.5444e-03,  4.7877e-04,\n",
      "         -1.7897e-03,  6.4512e-04, -7.9758e-04,  1.6696e-04,  8.5771e-05,\n",
      "         -9.5077e-05, -2.1201e-03, -5.8115e-04,  1.3861e-03,  3.9274e-04,\n",
      "          3.3460e-03,  1.3251e-03,  9.5144e-04, -5.0194e-05,  1.7954e-03,\n",
      "          1.2147e-03,  1.2353e-03, -1.1692e-03,  6.0145e-04,  1.2817e-04,\n",
      "         -7.2338e-04, -2.8768e-03, -4.4344e-04, -7.9797e-04, -1.3198e-03,\n",
      "          2.7037e-04, -1.4500e-03, -2.6825e-03,  1.1766e-03, -6.8262e-04,\n",
      "          3.4059e-03, -7.7245e-04,  1.0188e-02,  1.8128e-03,  4.6428e-03,\n",
      "         -4.5916e-03,  6.6008e-05, -8.3319e-04, -1.6525e-05, -2.6633e-03,\n",
      "         -9.8489e-04,  1.2331e-03, -2.2928e-03, -2.2062e-03,  3.7919e-03,\n",
      "         -8.5122e-04,  3.0559e-03, -2.4053e-04, -5.1789e-03,  1.2263e-03,\n",
      "          2.0592e-03, -1.7194e-03, -3.1070e-04,  2.3134e-03,  2.0199e-03,\n",
      "          3.2332e-03,  4.2918e-04,  5.4146e-04, -4.9895e-04, -1.3648e-03,\n",
      "         -1.3592e-03, -3.1225e-04,  6.4198e-04, -4.1605e-04,  8.5601e-04,\n",
      "          3.4832e-04,  1.2255e-04, -1.0242e-04,  5.9660e-04,  3.1606e-03,\n",
      "          6.4432e-04,  3.1473e-03, -2.0478e-03,  4.4269e-04, -8.5860e-04,\n",
      "          4.3595e-04,  1.4648e-04,  2.6736e-03],\n",
      "        [-6.9273e-04, -5.4966e-04, -1.9332e-03,  5.2081e-03, -1.1864e-03,\n",
      "         -1.5772e-03, -1.7188e-03, -2.7385e-04,  1.1332e-03, -8.5344e-04,\n",
      "         -1.7083e-04,  1.7728e-03, -6.2339e-04,  2.0354e-04,  1.8995e-03,\n",
      "          1.1867e-03, -2.0538e-03, -2.8206e-03,  9.0479e-04, -9.7290e-05,\n",
      "          5.9522e-04,  2.6058e-04,  9.2653e-04,  1.4593e-03,  1.7113e-03,\n",
      "          2.3145e-03,  3.8165e-03,  4.7879e-03, -3.6519e-03,  2.3051e-03,\n",
      "         -2.1084e-03, -1.5883e-03,  2.5233e-03,  1.6334e-03, -1.7795e-03,\n",
      "         -6.6669e-04, -9.0799e-04,  3.9673e-03, -1.9134e-03, -1.0540e-04,\n",
      "          3.3996e-04, -1.7660e-03,  3.4694e-03, -6.1979e-03,  1.6483e-03,\n",
      "          1.4605e-04,  5.0300e-04, -5.6037e-04,  5.1903e-03,  8.9018e-04,\n",
      "         -1.1440e-03, -1.9601e-03, -7.8176e-04,  3.4772e-03, -2.7907e-03,\n",
      "         -3.3504e-03, -2.4388e-03, -6.8311e-04,  9.8846e-04,  1.6661e-03,\n",
      "          5.0811e-03,  2.6208e-03, -3.9773e-03, -2.0099e-03,  2.3201e-03,\n",
      "          3.2487e-03, -6.2790e-03, -7.0264e-04, -9.0137e-04,  4.7359e-03,\n",
      "          3.6351e-04, -1.5785e-03, -1.4796e-03,  6.1572e-04, -1.5784e-03,\n",
      "          4.0040e-03,  1.7671e-03, -7.2283e-03,  1.4630e-03, -1.3707e-03,\n",
      "          7.3195e-03,  1.6803e-03,  3.9386e-04,  1.9755e-03,  2.9586e-03,\n",
      "         -5.7840e-04, -1.8783e-04,  1.9805e-04, -1.3276e-03, -3.0894e-04,\n",
      "         -3.9963e-03, -3.9045e-03, -1.3648e-03, -2.2169e-03, -3.2607e-03,\n",
      "          2.8585e-03,  4.7020e-03,  9.8144e-04, -5.6833e-03,  2.5127e-03,\n",
      "          1.1157e-03,  3.0695e-03,  5.7188e-04,  1.8114e-03,  7.8163e-04,\n",
      "          8.8542e-04, -2.8227e-03,  3.3425e-04, -1.8124e-03,  1.5034e-04,\n",
      "          9.5423e-04,  1.9051e-03,  1.6607e-03, -1.5758e-04,  1.5881e-04,\n",
      "          8.6816e-04,  4.2547e-03,  7.2385e-04, -3.8379e-04,  1.9472e-03,\n",
      "         -1.4536e-03,  4.6404e-03, -2.4857e-03, -1.9602e-03,  2.9647e-04,\n",
      "         -3.0715e-03,  3.8418e-03,  2.0684e-03],\n",
      "        [ 1.0735e-04, -3.5673e-05,  4.3684e-04,  2.2003e-03, -3.7637e-03,\n",
      "         -3.1425e-03, -1.0376e-03, -3.0624e-03, -1.7814e-03,  1.0311e-03,\n",
      "          8.3239e-04,  2.7345e-03, -2.6895e-03,  2.4551e-04, -4.1999e-04,\n",
      "          5.3260e-04, -4.3118e-04, -1.8194e-03,  9.8318e-05,  1.2031e-03,\n",
      "         -9.0852e-05, -2.4760e-04, -5.1232e-04, -5.7758e-04,  1.6801e-03,\n",
      "         -3.3371e-05,  2.0444e-03,  1.3765e-03, -2.5709e-03,  3.0676e-03,\n",
      "         -2.6110e-03, -1.7861e-04,  2.7178e-03, -4.6287e-04,  4.8956e-04,\n",
      "          2.5308e-03, -7.6888e-04,  1.8941e-03, -3.4288e-03, -6.4874e-04,\n",
      "          2.5053e-03,  2.4238e-03,  9.5616e-04, -3.5020e-03, -6.3094e-04,\n",
      "          7.7467e-05,  4.5753e-04,  4.6962e-04,  3.1687e-03,  2.2600e-05,\n",
      "         -2.9988e-03,  8.4013e-05,  2.6562e-04,  2.6413e-03, -1.0720e-03,\n",
      "         -2.2493e-03, -5.9746e-04, -2.3070e-03,  2.5497e-04,  2.5424e-03,\n",
      "          2.0179e-03,  2.1253e-03, -2.6248e-03, -6.7885e-04,  2.7392e-03,\n",
      "          1.8875e-03, -2.1850e-03,  1.5227e-04, -3.0261e-04,  8.7306e-05,\n",
      "         -5.2484e-04, -7.4827e-04,  1.3314e-04,  2.4507e-03, -1.3479e-03,\n",
      "          1.5954e-03,  3.9152e-04, -2.5603e-03,  2.9633e-03, -1.8620e-03,\n",
      "          8.7729e-04,  1.2215e-04,  1.2907e-03,  2.7656e-03,  2.6947e-03,\n",
      "         -1.0912e-03, -3.5010e-04, -3.6136e-03, -3.7801e-04, -3.7379e-03,\n",
      "         -2.6753e-03, -2.0544e-03, -5.9541e-04, -3.7972e-03,  1.7420e-03,\n",
      "         -8.1305e-04,  2.9827e-03, -6.0119e-04,  1.7249e-03,  3.5768e-03,\n",
      "          4.7696e-04, -1.1249e-03,  1.9729e-04,  2.9757e-03,  1.0677e-04,\n",
      "          3.4291e-03, -2.9769e-03,  1.5091e-04, -9.2804e-04, -6.1506e-04,\n",
      "         -8.0746e-04,  2.6667e-04, -1.2485e-04,  5.3841e-04, -6.1854e-04,\n",
      "          6.3483e-04,  2.4883e-03,  4.9184e-04,  3.4906e-03,  3.4252e-03,\n",
      "         -2.7493e-05,  2.2012e-03, -9.7223e-05,  5.8075e-04,  9.1717e-06,\n",
      "         -4.2948e-03,  2.4354e-03,  2.6174e-05]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([ 0.0030, -0.0027,  0.0054,  0.0009], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_pol = torch.load(RUN_FOLDER + '/models/policy.pt')\n",
    "for i,j in zip(new_pol.parameters(), agent.actor_critic.policy.parameters()):\n",
    "    print(i-j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_enc = torch.load(RUN_FOLDER + '/models/encoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_enc = torch.load(RUN_FOLDER + '/models/encoder.pt')\n",
    "for i,j in zip(new_enc.parameters(), agent.actor_critic.encoder.parameters()):\n",
    "    print(i-j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499: done!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/grant/working_repos/varibad/continual_learning_scratch.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbox.x.agi.io/home/grant/working_repos/varibad/continual_learning_scratch.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     _, latent_mean, latent_logvar, hidden_state \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mactor_critic\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mprior(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbox.x.agi.io/home/grant/working_repos/varibad/continual_learning_scratch.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# add this initial hidden state to the policy storage\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbox.x.agi.io/home/grant/working_repos/varibad/continual_learning_scratch.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(storage\u001b[39m.\u001b[39mlatent) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# make sure we emptied buffers\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbox.x.agi.io/home/grant/working_repos/varibad/continual_learning_scratch.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m storage\u001b[39m.\u001b[39mhidden_states[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcopy_(hidden_state\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbox.x.agi.io/home/grant/working_repos/varibad/continual_learning_scratch.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m latent \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((latent_mean\u001b[39m.\u001b[39mclone(), latent_logvar\u001b[39m.\u001b[39mclone()), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from algorithms.custom_storage import CustomOnlineStorage\n",
    "from algorithms.custom_ppo import CustomPPO\n",
    "# combined network with encoder + policy\n",
    "ac = ActorCritic(policy_net, encoder_net)\n",
    "agent = CustomPPO(\n",
    "    actor_critic=ac,\n",
    "    value_loss_coef = 1,\n",
    "    entropy_coef = 0.001,\n",
    "    policy_optimiser='adam',\n",
    "    policy_anneal_lr=False,\n",
    "    train_steps = 2,\n",
    "    lr = 0.001,\n",
    "    eps=1.0e-8,\n",
    "    clip_param = 0.2,\n",
    "    ppo_epoch = 3,\n",
    "    use_huber_loss = True,\n",
    "    use_clipped_value_loss=True,\n",
    "    context_window=None\n",
    ")\n",
    "env = training_envs[0]\n",
    "\n",
    "storage = CustomOnlineStorage(\n",
    "    500, 1, env.observation_space.shape[0]+1, 0, 0,\n",
    "    env.action_space, ac.encoder.hidden_size, ac.encoder.latent_dim, False)\n",
    "\n",
    "# get it going\n",
    "NUM_EP = 10\n",
    "# reward = action = hidden_state = None\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_steps = 0\n",
    "\n",
    "for i in range(NUM_EP):\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    # get the prior\n",
    "    with torch.no_grad():\n",
    "        _, latent_mean, latent_logvar, hidden_state = agent.actor_critic.encoder.prior(1)\n",
    "\n",
    "    # add this initial hidden state to the policy storage\n",
    "    assert len(storage.latent) == 0  # make sure we emptied buffers\n",
    "    storage.hidden_states[0].copy_(hidden_state.squeeze(1))\n",
    "    latent = torch.cat((latent_mean.clone(), latent_logvar.clone()), dim=-1).reshape(1, -1)\n",
    "    storage.latent.append(latent)\n",
    "\n",
    "    ## TODO: put this into the environment wrapper\n",
    "    obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1)).to(device)[None,:,:]\n",
    "    # next_state = torch.from_numpy(np.append(next_obs, 0).reshape(1, -1)).to(device)\n",
    "    # reward = torch.from_numpy(np.array(reward).reshape(1, -1)).float().to(device)\n",
    "    ## initial rewards + actions\n",
    "    # reward = torch.zeros(1, 1, 1).float().to(device)\n",
    "    # action = torch.zeros(1, 1, env.action_space.shape[0]).float().to(device)\n",
    "    step = 0\n",
    "    while not done:\n",
    "\n",
    "        # print(reward)\n",
    "        ## TODO: don't save this hidden state / latent, build them using this action + reward etc\n",
    "        # value, act, hidden_state, latent = agent.act(action, obs.float(), reward, hidden_state)\n",
    "        # value, act = agent.actor_critic.policy.act(obs.float(), latent, None, None)\n",
    "        value, act = agent.act(obs.float(), latent, None, None)\n",
    "        action = act.cpu().detach().numpy()[0]\n",
    "        # print(hidden_state)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        ## TODO: Tidy all of this up. Use environment wrappers to convert outputs to torch formats\n",
    "        obs = next_obs\n",
    "        next_state = torch.from_numpy(np.append(next_obs, 0).reshape(1, -1)).to(device)\n",
    "        reward = torch.from_numpy(np.array(reward).reshape(1, -1)).float().to(device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        ## don't worry about this for now\n",
    "        episode_reward += reward\n",
    "        episode_steps += 1\n",
    "\n",
    "        # create mask for episode ends\n",
    "        masks_done = torch.FloatTensor([[0.0] if done else [1.0] ]).to(device)\n",
    "        # bad_mask is true if episode ended because time limit was reached\n",
    "        # don't care for metaworld\n",
    "        bad_masks = torch.FloatTensor([[0.0]]).to(device)\n",
    "\n",
    "        # TODO: convert reset_hidden to actor critic level\n",
    "        if done:\n",
    "            print(f'{step}: done!')\n",
    "            hidden_state = agent.actor_critic.encoder.reset_hidden(hidden_state, masks_done)\n",
    "\n",
    "        # update encoding\n",
    "        # TODO: convert this to actor critic level\n",
    "        _, latent_mean, latent_logvar, hidden_state = agent.actor_critic.encoder(act, next_state.float(), reward, hidden_state, return_prior = False)\n",
    "        latent = torch.cat((latent_mean.clone(), latent_logvar.clone()), dim = -1).reshape(1, -1)\n",
    "\n",
    "        \n",
    "        storage.next_state[step] = next_state.clone()\n",
    "\n",
    "        storage.insert(\n",
    "            state=next_state,\n",
    "            belief=None,\n",
    "            task=None,\n",
    "            actions=act,\n",
    "            rewards_raw=reward,\n",
    "            rewards_normalised=reward,#rew_normalised,\n",
    "            value_preds=value,\n",
    "            masks=masks_done,\n",
    "            bad_masks=bad_masks,\n",
    "            done=torch.from_numpy(np.array(done, dtype=float)),\n",
    "            hidden_states = hidden_state.squeeze(1),\n",
    "            latent = latent#.unsqueeze(1),\n",
    "        )\n",
    "        ## TODO: put this into the environment wrapper\n",
    "        obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1)).to(device)[None,:,:]\n",
    "        # reward = reward.to(device)\n",
    "        action = torch.from_numpy(action)[None, None,:].to(device)\n",
    "\n",
    "        ## update step\n",
    "        step +=1\n",
    "# s, m, l, h = ac.encoder.prior(np.append(obs, 0).reshape(1, -1).shape[1])\n",
    "# print(s.shape, m.shape, l.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1022,  0.9432, -0.7806, -0.0911]],\n",
       "\n",
       "        [[ 0.8372,  0.7709, -0.4821,  0.5857]],\n",
       "\n",
       "        [[ 1.5242, -0.4840, -0.2182,  0.8799]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-6.4956, -0.8461, -0.6892, -2.3175]],\n",
       "\n",
       "        [[-7.2733,  0.2684, -2.3687, -2.1775]],\n",
       "\n",
       "        [[-5.8726, -0.0479, -3.1331, -2.1457]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.before_update(agent.actor_critic.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- get action values --\n",
    "advantages = storage.returns[:-1] - storage.value_preds[:-1]\n",
    "advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-5)\n",
    "\n",
    "# recompute embeddings (to build computation graph)\n",
    "# agent._recompute_embeddings(storage, sample=False, update_idx=0,\n",
    "#                     detach_every= agent.context_window if agent.context_window is not None else None)\n",
    "\n",
    "# update the normalisation parameters of policy inputs before updating\n",
    "# don't think I need this\n",
    "# self.actor_critic.update_rms(args=self.args, policy_storage=policy_storage)\n",
    "\n",
    "# call this to make sure that the action_log_probs are computed\n",
    "# (needs to be done right here because of some caching thing when normalising actions)\n",
    "storage.before_update(agent.actor_critic)\n",
    "\n",
    "value_loss_epoch = 0\n",
    "action_loss_epoch = 0\n",
    "dist_entropy_epoch = 0\n",
    "loss_epoch = 0\n",
    "for e in range(agent.ppo_epoch):\n",
    "\n",
    "    data_generator = storage.feed_forward_generator(advantages, 20)\n",
    "    for sample in data_generator:\n",
    "\n",
    "        state_batch, actions_batch, latent_batch, value_preds_batch, \\\n",
    "        return_batch, old_action_log_probs_batch, adv_targ = sample\n",
    "        break\n",
    "        # # if not rlloss_through_encoder:\n",
    "        # # state_batch = state_batch.detach()\n",
    "        # ## TODO: I think I should not detach this\n",
    "        # latent_batch = latent_batch#.detach()\n",
    "\n",
    "        # # Reshape to do in a single forward pass for all steps\n",
    "        # values, action_log_probs, dist_entropy = \\\n",
    "        #     agent.actor_critic.evaluate_actions(state=state_batch, latent=latent_batch,\n",
    "        #                                         belief=None, task=None,\n",
    "        #                                         action=actions_batch)\n",
    "        # # break\n",
    "        # ratio = torch.exp(action_log_probs.double() -\n",
    "        #                     old_action_log_probs_batch.double())\n",
    "        # # break\n",
    "\n",
    "        # surr1 = ratio * adv_targ\n",
    "        # surr2 = torch.clamp(ratio, 1.0 - agent.clip_param, 1.0 + agent.clip_param) * adv_targ\n",
    "        # action_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "        # if agent.use_huber_loss and agent.use_clipped_value_loss:\n",
    "        #     value_pred_clipped = value_preds_batch + (values - value_preds_batch).clamp(-agent.clip_param,\n",
    "        #                                                                                 agent.clip_param)\n",
    "        #     value_losses = F.smooth_l1_loss(values, return_batch, reduction='none')\n",
    "        #     value_losses_clipped = F.smooth_l1_loss(value_pred_clipped, return_batch, reduction='none')\n",
    "        #     value_loss = 0.5 * torch.max(value_losses, value_losses_clipped).mean()\n",
    "        # elif agent.use_huber_loss:\n",
    "        #     value_loss = F.smooth_l1_loss(values, return_batch)\n",
    "        # elif agent.use_clipped_value_loss:\n",
    "        #     value_pred_clipped = value_preds_batch + (values - value_preds_batch).clamp(-agent.clip_param,\n",
    "        #                                                                                 agent.clip_param)\n",
    "        #     value_losses = (values - return_batch).pow(2)\n",
    "        #     value_losses_clipped = (value_pred_clipped - return_batch).pow(2)\n",
    "        #     value_loss = 0.5 * torch.max(value_losses, value_losses_clipped).mean()\n",
    "        # else:\n",
    "        #     value_loss = 0.5 * (return_batch - values).pow(2).mean()\n",
    "\n",
    "        # # zero out the gradients\n",
    "        # agent.optimiser.zero_grad()\n",
    "\n",
    "        # # compute policy loss and backprop\n",
    "        # loss = value_loss * agent.value_loss_coef + action_loss - dist_entropy * agent.entropy_coef\n",
    "\n",
    "        # # compute vae loss and backprop\n",
    "        # # if rlloss_through_encoder:\n",
    "        # #     loss += self.args.vae_loss_coeff * compute_vae_loss()\n",
    "\n",
    "        # # compute gradients (will attach to all networks involved in this computation)\n",
    "        # loss.backward()\n",
    "\n",
    "        # # clip gradients\n",
    "        # nn.utils.clip_grad_norm_(agent.actor_critic.parameters(), agent.max_grad_norm)\n",
    "        # # nn.utils.clip_grad_norm_(self.actor_critic.parameters(), self.args.policy_max_grad_norm)\n",
    "\n",
    "        # # in oursetup loss is always through encoder\n",
    "        # # if rlloss_through_encoder:\n",
    "        # #     if self.args.encoder_max_grad_norm is not None:\n",
    "        # #         nn.utils.clip_grad_norm_(encoder.parameters(), self.args.encoder_max_grad_norm)\n",
    "\n",
    "\n",
    "\n",
    "        # value_loss_epoch += value_loss.item()\n",
    "        # action_loss_epoch += action_loss.item()\n",
    "        # dist_entropy_epoch += dist_entropy.item()\n",
    "        # loss_epoch += loss.item()\n",
    "        # print(value_loss, action_loss, dist_entropy, loss_epoch)\n",
    "\n",
    "        # # if rlloss_through_encoder:\n",
    "        # # recompute embeddings (to build computation graph) during updates\n",
    "        # agent._recompute_embeddings(storage, sample=False, update_idx=e + 1,\n",
    "        #                                 detach_every= agent.context_window if agent.context_window is not None else None)\n",
    "        # # utl.recompute_embeddings(policy_storage, encoder, sample=False, update_idx=e + 1,\n",
    "        # #                              detach_every= self.context_window if self.context_window is not None else None)\n",
    "\n",
    "\n",
    "\n",
    "# num_updates = agent.ppo_epoch * agent.num_mini_batch\n",
    "\n",
    "# value_loss_epoch /= num_updates\n",
    "# action_loss_epoch /= num_updates\n",
    "# dist_entropy_epoch /= num_updates\n",
    "# loss_epoch /= num_updates\n",
    "\n",
    "# print(value_loss_epoch, action_loss_epoch, dist_entropy_epoch, loss_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.2927],\n",
       "        [-4.2247],\n",
       "        [-6.2750],\n",
       "        [-5.2253],\n",
       "        [-8.0187],\n",
       "        [-5.4290],\n",
       "        [-5.0772],\n",
       "        [-5.4263],\n",
       "        [-5.0073],\n",
       "        [-3.8443],\n",
       "        [-3.8643],\n",
       "        [-3.0122],\n",
       "        [-4.9928],\n",
       "        [-3.4717],\n",
       "        [-4.3290],\n",
       "        [-5.1013],\n",
       "        [-4.5723],\n",
       "        [-4.4251],\n",
       "        [-3.0582],\n",
       "        [-5.7388],\n",
       "        [-6.0885],\n",
       "        [-9.1335],\n",
       "        [-3.9071],\n",
       "        [-3.8661],\n",
       "        [-2.8272]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_action_log_probs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9305963039398193,\n",
       " 0.07060316515465577,\n",
       " 4.6715317090352375,\n",
       " 1.9965279340744018)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.update(storage, encoder= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0054,  0.0014, -0.0019,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0044, -0.0025, -0.0013,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0038, -0.0006,  0.0004,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0024,  0.0020,  0.0018,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([ 0.0025, -0.0035,  0.0000, -0.0042, -0.0001,  0.0004, -0.0019, -0.0015,\n",
      "        -0.0047, -0.0004,  0.0046,  0.0043,  0.0000, -0.0018, -0.0041,  0.0038,\n",
      "         0.0023, -0.0018, -0.0038,  0.0000,  0.0000,  0.0033,  0.0024,  0.0032,\n",
      "         0.0000,  0.0000, -0.0037,  0.0000,  0.0024,  0.0000, -0.0015,  0.0020],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[ 2.7781e-03,  7.0907e-03, -1.1182e-02, -1.0534e-03],\n",
      "        [ 3.2067e-04, -2.4065e-03,  1.1017e-02,  3.3087e-03],\n",
      "        [ 3.4662e-03,  6.5446e-03,  2.4032e-03,  3.0088e-03],\n",
      "        [ 2.3399e-03,  4.1417e-03, -2.7430e-03,  1.5666e-03],\n",
      "        [ 4.3709e-03,  4.8538e-03, -3.6398e-04,  4.2774e-03],\n",
      "        [-3.9213e-03, -2.3183e-04,  1.6656e-03, -3.5374e-03],\n",
      "        [ 4.7454e-04,  7.4911e-04, -1.2635e-03,  1.2974e-03],\n",
      "        [-6.1758e-04,  3.4070e-04, -4.7295e-03, -4.6321e-03],\n",
      "        [ 5.3057e-03,  6.7848e-03, -6.3810e-03,  3.2478e-03],\n",
      "        [ 4.2410e-03,  7.8857e-03,  3.0859e-03,  2.4934e-03],\n",
      "        [-1.8007e-03,  2.2484e-03, -2.0565e-03, -2.3389e-03],\n",
      "        [-3.9811e-03, -5.2320e-03,  8.9331e-03, -3.2082e-03],\n",
      "        [-4.9675e-03, -5.0023e-03, -2.0752e-03, -4.8871e-03],\n",
      "        [-8.8260e-04, -1.7488e-03, -8.9857e-04, -2.7326e-03],\n",
      "        [ 2.7991e-03,  3.2933e-03,  1.7600e-03,  7.3966e-04],\n",
      "        [-2.5282e-03,  9.1195e-05,  1.2433e-03,  7.9575e-04]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([ 0.0061,  0.0007, -0.0024,  0.0012,  0.0052, -0.0003,  0.0018, -0.0028,\n",
      "         0.0053, -0.0051,  0.0019, -0.0040,  0.0014, -0.0007, -0.0040,  0.0029],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[ 0.0000e+00],\n",
      "        [ 0.0000e+00],\n",
      "        [ 0.0000e+00],\n",
      "        [-2.9907e-03],\n",
      "        [-1.4074e-03],\n",
      "        [-1.0948e-03],\n",
      "        [-2.1813e-03],\n",
      "        [ 2.7594e-04],\n",
      "        [ 0.0000e+00],\n",
      "        [ 0.0000e+00],\n",
      "        [-1.1923e-03],\n",
      "        [ 6.1825e-04],\n",
      "        [-1.3831e-04],\n",
      "        [-1.2870e-03],\n",
      "        [-2.8980e-04],\n",
      "        [ 8.8930e-05]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4135e-03, -1.7481e-03,\n",
      "        -1.1281e-03, -3.3021e-03,  3.8892e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -1.7587e-03,  8.3375e-04, -2.2769e-05, -1.5169e-03, -5.3477e-04,\n",
      "        -3.1659e-04], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[ 0.0008,  0.0007, -0.0015,  ...,  0.0002, -0.0033, -0.0026],\n",
      "        [-0.0042, -0.0046,  0.0057,  ...,  0.0010, -0.0024, -0.0038],\n",
      "        [-0.0012, -0.0006, -0.0019,  ..., -0.0030,  0.0041,  0.0033],\n",
      "        ...,\n",
      "        [ 0.0032,  0.0042,  0.0025,  ...,  0.0045, -0.0006, -0.0008],\n",
      "        [ 0.0025,  0.0028, -0.0031,  ..., -0.0003,  0.0025,  0.0016],\n",
      "        [ 0.0024,  0.0022,  0.0006,  ...,  0.0014,  0.0013,  0.0011]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[-0.0011,  0.0036,  0.0021,  ..., -0.0004,  0.0034, -0.0008],\n",
      "        [-0.0053, -0.0029, -0.0068,  ..., -0.0064,  0.0054,  0.0076],\n",
      "        [ 0.0024,  0.0031,  0.0008,  ..., -0.0001,  0.0038,  0.0005],\n",
      "        ...,\n",
      "        [-0.0022, -0.0060, -0.0010,  ..., -0.0041,  0.0077,  0.0032],\n",
      "        [ 0.0045,  0.0057,  0.0044,  ...,  0.0014,  0.0079, -0.0031],\n",
      "        [-0.0006, -0.0036, -0.0025,  ..., -0.0015,  0.0055,  0.0036]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([ 8.3523e-04,  2.3336e-03, -3.1788e-03,  4.6627e-03,  1.2345e-03,\n",
      "         3.1567e-03,  1.6335e-03,  5.0003e-03,  9.7299e-04, -2.1813e-03,\n",
      "        -5.0813e-03,  2.8142e-04,  8.6508e-03, -3.9354e-03,  3.4724e-03,\n",
      "        -2.5801e-03, -6.0240e-03,  3.6223e-03, -2.8050e-03,  6.9402e-03,\n",
      "         2.5864e-04, -2.4358e-03,  1.2548e-03, -5.1268e-03,  4.7865e-03,\n",
      "        -3.2030e-03, -8.1079e-04,  8.6374e-03, -1.6074e-03, -2.8998e-03,\n",
      "        -3.8019e-03,  9.9519e-03,  3.5005e-03, -3.9459e-03,  5.8814e-04,\n",
      "        -4.6859e-04, -4.2426e-03, -3.1893e-03, -5.6034e-03, -7.3021e-03,\n",
      "        -5.3410e-04, -6.3451e-03,  4.2524e-04,  6.2199e-03,  4.3374e-03,\n",
      "         5.2263e-03,  2.6229e-03, -2.7390e-03,  2.0081e-03,  2.3399e-03,\n",
      "        -4.1316e-03, -6.1234e-03, -6.7997e-03, -4.5493e-03, -2.0264e-03,\n",
      "        -5.9288e-03, -4.1169e-03,  4.2415e-04, -1.0490e-03, -6.9404e-04,\n",
      "        -2.5993e-03, -3.1591e-03,  7.4722e-04, -1.2769e-03,  1.5978e-03,\n",
      "         2.2400e-05,  2.2882e-03,  5.7480e-04,  9.6362e-04, -5.6072e-03,\n",
      "         5.8241e-03, -3.0427e-03,  2.0402e-04,  4.9880e-03, -2.1278e-03,\n",
      "        -6.4762e-04,  4.7265e-04, -3.6024e-03, -4.4145e-03,  3.2359e-03,\n",
      "        -3.6117e-03,  1.1967e-03, -1.4873e-03,  5.8061e-03,  5.9159e-03,\n",
      "         3.6918e-03, -6.6035e-04, -1.4368e-03, -9.9321e-04,  7.8577e-04,\n",
      "        -6.0742e-04, -4.5027e-03,  2.9081e-03, -4.2104e-03, -5.0450e-04,\n",
      "         5.3793e-03, -1.7180e-03, -2.7059e-03, -4.2203e-04,  2.0009e-03,\n",
      "        -4.2990e-03,  1.4958e-03, -2.8370e-03,  3.1894e-03,  3.0573e-04,\n",
      "        -1.9763e-03, -1.0217e-03, -9.5276e-03,  7.0162e-03, -1.2447e-03,\n",
      "        -5.0162e-03, -4.9698e-03, -3.4293e-03, -7.8405e-04,  2.0818e-03,\n",
      "        -5.5791e-03,  6.3425e-03,  9.6740e-04,  2.0007e-03,  1.4710e-03,\n",
      "        -2.5910e-03, -3.1534e-03,  1.3388e-03, -1.9425e-03,  6.7818e-04,\n",
      "         1.4262e-03,  2.7620e-03,  1.2016e-03,  4.2039e-03,  2.7322e-03,\n",
      "         5.8714e-03,  5.1623e-03,  2.9318e-03, -5.2666e-04, -5.3239e-03,\n",
      "         2.4979e-03,  7.8590e-03,  3.2479e-03,  8.4498e-03, -4.4798e-03,\n",
      "         1.1249e-03, -5.7980e-03, -2.7433e-03, -2.7382e-03, -2.6117e-03,\n",
      "        -3.2757e-03,  7.7215e-03,  8.5504e-03,  9.0034e-04,  7.1273e-03,\n",
      "        -3.6654e-03,  8.1603e-04,  3.2776e-03,  5.7296e-03, -3.0401e-03,\n",
      "         2.9352e-03,  2.5998e-04,  4.1030e-05, -3.7655e-03, -1.3168e-03,\n",
      "         4.6525e-03, -1.4493e-03,  6.6577e-03, -4.2832e-03,  7.0946e-03,\n",
      "         4.1548e-03, -5.4740e-03,  4.8374e-03,  3.1434e-03,  5.3497e-03,\n",
      "         8.1377e-03,  5.8253e-03,  8.1218e-03, -3.0924e-03, -4.5430e-03,\n",
      "         6.3405e-03,  1.2538e-03, -6.2936e-03,  3.0433e-03,  1.2262e-03,\n",
      "        -4.1022e-03,  7.0816e-03,  5.7520e-03, -2.6355e-03,  5.4298e-03,\n",
      "         4.1749e-03,  3.5906e-03,  7.7690e-03,  3.4187e-03,  4.0024e-03,\n",
      "         5.5525e-04,  4.3923e-03,  5.3736e-03,  7.2507e-03,  1.5419e-03,\n",
      "         3.8289e-03, -1.2297e-03,  5.8558e-03, -8.0424e-03,  3.4194e-03,\n",
      "        -3.2104e-03,  3.5905e-03,  7.2533e-03,  8.1979e-03,  4.1054e-03,\n",
      "         7.9738e-03,  7.2952e-03,  5.1229e-03, -3.7237e-03,  6.0680e-03,\n",
      "         2.3209e-03,  4.9531e-03,  1.0333e-02,  5.3533e-03, -1.2436e-03,\n",
      "         2.8648e-03,  3.9974e-03,  3.3131e-03,  6.2636e-03,  6.8999e-03,\n",
      "         5.0029e-03,  1.7473e-03,  7.4555e-03,  3.9370e-03, -9.1123e-04,\n",
      "         4.6743e-03, -5.8263e-03, -8.0275e-03, -2.4994e-03,  3.8877e-03,\n",
      "         4.4887e-03,  6.9080e-03, -4.9622e-04,  7.2636e-03, -6.0007e-03,\n",
      "        -1.1588e-03,  7.8583e-03, -8.6704e-03,  8.4175e-03, -4.6263e-03,\n",
      "        -1.7675e-03,  5.0934e-03, -3.4960e-03,  1.0023e-03, -7.3650e-04,\n",
      "        -6.7580e-03, -4.3754e-03, -8.6428e-03,  7.4551e-03,  6.4543e-03,\n",
      "        -3.2593e-03,  1.0020e-03, -3.2492e-03,  1.3435e-03, -5.5957e-03,\n",
      "         4.5475e-03,  7.1041e-06, -5.7026e-03, -2.1577e-03,  4.0153e-03,\n",
      "         1.5920e-03, -1.4341e-03,  3.2174e-03,  4.8189e-03, -3.6131e-03,\n",
      "         2.3204e-03,  1.1204e-03,  2.3885e-03, -2.4066e-03, -3.4205e-03,\n",
      "         8.2529e-04, -1.3761e-03, -1.9463e-03,  3.1091e-03,  3.2292e-03,\n",
      "        -1.1398e-04,  2.6379e-03, -1.5428e-03, -3.2857e-03, -3.0907e-03,\n",
      "        -3.9557e-03,  1.8183e-03, -3.0381e-04, -1.5261e-03,  4.5429e-04,\n",
      "         1.4964e-03, -2.9010e-03, -1.7439e-03, -1.7932e-03, -2.2371e-03,\n",
      "        -6.2985e-05,  2.9187e-03,  8.9009e-04,  2.9420e-03, -4.2176e-03,\n",
      "         1.2757e-03,  4.5016e-04, -7.7111e-04, -4.0717e-03,  2.0168e-03,\n",
      "        -4.9522e-03,  3.7833e-03, -3.3859e-03,  4.1274e-03, -2.1847e-03,\n",
      "        -3.9986e-03,  3.3374e-03,  1.2266e-03, -1.3604e-03,  2.3231e-03,\n",
      "         4.8098e-04, -2.1686e-03, -3.0674e-03,  2.1953e-03,  2.4308e-03,\n",
      "         3.0401e-04,  6.4371e-03, -4.9464e-04,  8.9484e-04, -5.4321e-04,\n",
      "         5.1668e-04, -3.1367e-03,  9.0390e-04,  5.3700e-03, -1.3192e-03,\n",
      "        -1.0392e-03,  4.5337e-03,  2.3782e-03, -1.2142e-03, -3.5116e-03,\n",
      "        -1.0469e-03, -4.5391e-03, -2.6748e-03,  5.8594e-04, -2.0487e-04,\n",
      "        -3.4789e-03,  3.6162e-04,  1.6050e-03, -1.0280e-04,  6.0185e-03,\n",
      "         2.5561e-03,  5.7069e-03,  2.7707e-03,  8.1164e-04,  1.9956e-03,\n",
      "        -2.9061e-03, -6.2374e-03, -7.7331e-04,  3.7187e-03, -2.8810e-03,\n",
      "        -4.3563e-03, -3.4837e-03, -3.3777e-03,  2.5125e-03,  3.7163e-03,\n",
      "         4.3523e-04, -1.1346e-03,  4.4089e-03, -5.8995e-03,  3.7818e-03,\n",
      "         3.5600e-03,  7.1723e-04, -1.6285e-03,  5.1793e-03, -2.9296e-03,\n",
      "        -3.3595e-03,  8.3988e-04,  1.0400e-03,  4.3229e-03, -5.2086e-04,\n",
      "        -3.0058e-05,  4.6960e-03,  3.1151e-03,  1.0316e-03, -2.3376e-03,\n",
      "         4.4937e-04, -3.0953e-03,  1.8539e-04, -1.5929e-03, -3.4941e-04,\n",
      "        -3.2409e-03,  4.8737e-03, -4.3614e-04,  1.5266e-03], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([ 8.3523e-04,  2.3336e-03, -3.1788e-03,  4.6627e-03,  1.2345e-03,\n",
      "         3.1567e-03,  1.6335e-03,  5.0003e-03,  9.7299e-04, -2.1813e-03,\n",
      "        -5.0813e-03,  2.8142e-04,  8.6508e-03, -3.9354e-03,  3.4724e-03,\n",
      "        -2.5801e-03, -6.0240e-03,  3.6223e-03, -2.8050e-03,  6.9402e-03,\n",
      "         2.5864e-04, -2.4358e-03,  1.2548e-03, -5.1268e-03,  4.7865e-03,\n",
      "        -3.2030e-03, -8.1079e-04,  8.6374e-03, -1.6074e-03, -2.8998e-03,\n",
      "        -3.8019e-03,  9.9519e-03,  3.5005e-03, -3.9459e-03,  5.8814e-04,\n",
      "        -4.6859e-04, -4.2426e-03, -3.1893e-03, -5.6034e-03, -7.3021e-03,\n",
      "        -5.3410e-04, -6.3451e-03,  4.2524e-04,  6.2199e-03,  4.3374e-03,\n",
      "         5.2263e-03,  2.6229e-03, -2.7390e-03,  2.0081e-03,  2.3399e-03,\n",
      "        -4.1316e-03, -6.1234e-03, -6.7997e-03, -4.5493e-03, -2.0264e-03,\n",
      "        -5.9288e-03, -4.1169e-03,  4.2415e-04, -1.0490e-03, -6.9404e-04,\n",
      "        -2.5993e-03, -3.1591e-03,  7.4722e-04, -1.2769e-03,  1.5978e-03,\n",
      "         2.2400e-05,  2.2882e-03,  5.7480e-04,  9.6362e-04, -5.6072e-03,\n",
      "         5.8241e-03, -3.0427e-03,  2.0402e-04,  4.9880e-03, -2.1278e-03,\n",
      "        -6.4762e-04,  4.7265e-04, -3.6024e-03, -4.4145e-03,  3.2359e-03,\n",
      "        -3.6117e-03,  1.1967e-03, -1.4873e-03,  5.8061e-03,  5.9159e-03,\n",
      "         3.6918e-03, -6.6035e-04, -1.4368e-03, -9.9321e-04,  7.8577e-04,\n",
      "        -6.0742e-04, -4.5027e-03,  2.9081e-03, -4.2104e-03, -5.0450e-04,\n",
      "         5.3793e-03, -1.7180e-03, -2.7059e-03, -4.2203e-04,  2.0009e-03,\n",
      "        -4.2990e-03,  1.4958e-03, -2.8370e-03,  3.1894e-03,  3.0573e-04,\n",
      "        -1.9763e-03, -1.0217e-03, -9.5276e-03,  7.0162e-03, -1.2447e-03,\n",
      "        -5.0162e-03, -4.9698e-03, -3.4293e-03, -7.8405e-04,  2.0818e-03,\n",
      "        -5.5791e-03,  6.3425e-03,  9.6740e-04,  2.0007e-03,  1.4710e-03,\n",
      "        -2.5910e-03, -3.1534e-03,  1.3388e-03, -1.9425e-03,  6.7818e-04,\n",
      "         1.4262e-03,  2.7620e-03,  1.2016e-03,  4.2039e-03,  2.7322e-03,\n",
      "         5.8714e-03,  5.1623e-03,  2.9318e-03, -5.2666e-04, -5.3239e-03,\n",
      "         2.4979e-03,  7.8590e-03,  3.2479e-03,  8.4498e-03, -4.4798e-03,\n",
      "         1.1249e-03, -5.7980e-03, -2.7433e-03, -2.7382e-03, -2.6117e-03,\n",
      "        -3.2757e-03,  7.7215e-03,  8.5504e-03,  9.0034e-04,  7.1273e-03,\n",
      "        -3.6654e-03,  8.1603e-04,  3.2776e-03,  5.7296e-03, -3.0401e-03,\n",
      "         2.9352e-03,  2.5998e-04,  4.1030e-05, -3.7655e-03, -1.3168e-03,\n",
      "         4.6525e-03, -1.4493e-03,  6.6577e-03, -4.2832e-03,  7.0946e-03,\n",
      "         4.1548e-03, -5.4740e-03,  4.8374e-03,  3.1434e-03,  5.3497e-03,\n",
      "         8.1377e-03,  5.8253e-03,  8.1218e-03, -3.0924e-03, -4.5430e-03,\n",
      "         6.3405e-03,  1.2538e-03, -6.2936e-03,  3.0433e-03,  1.2262e-03,\n",
      "        -4.1022e-03,  7.0816e-03,  5.7520e-03, -2.6355e-03,  5.4298e-03,\n",
      "         4.1749e-03,  3.5906e-03,  7.7690e-03,  3.4187e-03,  4.0024e-03,\n",
      "         5.5525e-04,  4.3923e-03,  5.3736e-03,  7.2507e-03,  1.5419e-03,\n",
      "         3.8289e-03, -1.2297e-03,  5.8558e-03, -8.0424e-03,  3.4194e-03,\n",
      "        -3.2104e-03,  3.5905e-03,  7.2533e-03,  8.1979e-03,  4.1054e-03,\n",
      "         7.9738e-03,  7.2952e-03,  5.1229e-03, -3.7237e-03,  6.0680e-03,\n",
      "         2.3209e-03,  4.9531e-03,  1.0333e-02,  5.3533e-03, -1.2436e-03,\n",
      "         2.8648e-03,  3.9974e-03,  3.3131e-03,  6.2636e-03,  6.8999e-03,\n",
      "         5.0029e-03,  1.7473e-03,  7.4555e-03,  3.9370e-03, -9.1123e-04,\n",
      "         4.6743e-03, -5.8263e-03, -8.0275e-03, -2.4994e-03,  3.8877e-03,\n",
      "         4.4887e-03,  6.9080e-03, -4.9622e-04,  7.2636e-03, -6.0007e-03,\n",
      "        -1.1588e-03,  7.8583e-03, -8.6704e-03,  8.4175e-03, -4.6263e-03,\n",
      "        -1.7675e-03,  5.0934e-03, -3.4960e-03,  1.0023e-03, -7.3650e-04,\n",
      "        -6.7580e-03, -4.3754e-03, -8.6428e-03,  7.4551e-03,  6.4543e-03,\n",
      "        -3.2593e-03,  1.0020e-03, -3.2492e-03,  1.3435e-03, -5.5957e-03,\n",
      "         4.5475e-03,  7.8548e-04, -6.3827e-03, -2.6577e-03,  3.4828e-03,\n",
      "        -8.2028e-04, -2.2615e-03,  4.2585e-03,  1.6393e-03, -3.0606e-03,\n",
      "         2.2837e-03,  4.5938e-04,  2.1312e-03, -2.8587e-03, -3.4640e-03,\n",
      "         1.2135e-03, -3.1607e-03, -2.6535e-03,  3.2635e-03,  3.0997e-03,\n",
      "        -3.2969e-03,  2.4499e-03, -2.2402e-03, -2.2107e-03, -3.3847e-03,\n",
      "        -4.2794e-03,  1.7273e-03, -9.8301e-05, -1.9166e-03, -1.7433e-03,\n",
      "         1.5555e-03, -3.0105e-03, -2.5469e-04, -1.7256e-03, -2.9665e-03,\n",
      "         6.4133e-04,  3.4317e-03,  1.0016e-03,  2.8632e-03, -4.4925e-03,\n",
      "         1.6394e-03,  1.0910e-03, -1.6475e-03, -4.0789e-03,  2.8795e-03,\n",
      "        -4.5145e-03,  3.8725e-03, -5.0608e-03,  3.0751e-03, -1.2462e-03,\n",
      "        -4.8989e-03,  3.5729e-03,  1.1468e-03, -1.5358e-03, -1.1407e-03,\n",
      "         1.2403e-03,  7.0438e-04, -2.7411e-03,  2.2226e-03,  2.6820e-03,\n",
      "         9.4865e-04,  6.3492e-03, -1.0831e-03,  7.8755e-05, -1.5987e-04,\n",
      "         4.0409e-04, -3.0413e-03,  8.1697e-04,  5.3041e-03, -1.1743e-03,\n",
      "        -1.7868e-03,  4.4838e-03,  2.5098e-03, -1.7809e-03, -3.6779e-03,\n",
      "        -1.4516e-03, -4.5059e-03, -2.0449e-03,  4.0609e-04, -7.3217e-04,\n",
      "        -5.1146e-03, -3.9055e-05,  3.0022e-03,  1.2904e-03,  6.1087e-03,\n",
      "         1.1995e-03,  6.1670e-03,  1.1937e-03,  6.0765e-04,  1.0696e-03,\n",
      "        -3.6233e-03, -5.9144e-03, -2.5348e-04,  3.8314e-03, -2.9905e-03,\n",
      "        -2.1239e-03, -3.7800e-03, -3.8435e-03,  2.3091e-03,  3.2783e-03,\n",
      "        -4.0662e-04, -9.5910e-04,  4.6659e-03, -6.1755e-03,  3.6720e-03,\n",
      "         4.1638e-03,  1.2876e-03, -1.5129e-03,  6.1330e-03, -4.2899e-03,\n",
      "        -3.0674e-03,  8.3074e-04, -1.5120e-04,  4.8117e-03, -2.1509e-03,\n",
      "        -2.5343e-03,  4.4334e-03,  3.3529e-03,  9.8249e-04, -2.9448e-03,\n",
      "        -9.9037e-05, -2.6765e-03,  9.7722e-04, -1.7435e-03, -3.1849e-04,\n",
      "        -1.9844e-03,  4.8139e-03,  1.4067e-03,  1.4932e-03], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[-0.0011, -0.0032,  0.0017,  ...,  0.0016,  0.0081, -0.0029],\n",
      "        [-0.0021, -0.0042, -0.0013,  ..., -0.0018,  0.0019,  0.0022],\n",
      "        [-0.0029, -0.0051, -0.0044,  ..., -0.0043, -0.0027,  0.0055],\n",
      "        ...,\n",
      "        [ 0.0014, -0.0023, -0.0017,  ...,  0.0016,  0.0009, -0.0012],\n",
      "        [-0.0017, -0.0038, -0.0026,  ..., -0.0018,  0.0022,  0.0025],\n",
      "        [-0.0016, -0.0037, -0.0049,  ...,  0.0001,  0.0021,  0.0012]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([ 4.7290e-03, -1.0748e-03, -1.9080e-03, -4.1451e-03, -2.8508e-03,\n",
      "         5.7485e-03,  1.1310e-05, -4.2318e-03, -7.8303e-04,  2.4714e-05,\n",
      "         1.7418e-03,  2.8180e-03, -5.8362e-03, -2.7039e-03,  9.3058e-04,\n",
      "         1.3173e-03,  2.5060e-03,  7.6862e-04, -3.0477e-03,  5.5913e-03,\n",
      "         5.8500e-03,  1.2609e-03,  6.7115e-03, -6.2973e-03, -6.0966e-03,\n",
      "         2.2748e-03, -3.0361e-03, -4.1062e-04, -4.3357e-03,  1.7204e-03,\n",
      "         2.8575e-03,  6.0841e-03,  1.6279e-03,  5.0105e-03,  2.8249e-03,\n",
      "         1.5141e-03,  9.7138e-04, -1.4520e-03,  4.9421e-05,  1.4825e-03,\n",
      "        -6.9468e-04,  4.6219e-03,  2.4201e-03, -7.6775e-03, -3.7000e-03,\n",
      "         3.3885e-03,  2.0287e-03, -1.6604e-03,  1.9734e-03,  1.4077e-03,\n",
      "         6.5858e-03,  1.5454e-04, -1.6217e-03,  8.7199e-04, -5.4394e-03,\n",
      "         3.5307e-03,  2.8801e-03,  1.0419e-03,  5.1577e-04,  4.1983e-03,\n",
      "         4.8577e-03,  5.5765e-03,  2.7694e-03, -3.6294e-03, -6.0264e-03,\n",
      "         8.3036e-03, -1.3804e-04,  3.5802e-03,  7.4689e-04,  2.0091e-03,\n",
      "         5.0959e-03,  4.9179e-03, -3.6976e-03,  5.4533e-03, -4.0656e-03,\n",
      "         2.8227e-03,  1.9098e-03,  1.7541e-03,  2.6671e-04,  6.2002e-03,\n",
      "        -4.3537e-03, -8.8269e-04, -3.4935e-03,  2.0807e-03, -2.9559e-03,\n",
      "        -5.2558e-03,  4.7083e-03, -7.1480e-03,  5.5481e-03, -2.0224e-04,\n",
      "         6.6253e-03, -3.4863e-03,  3.1023e-04, -4.4393e-03,  5.1161e-03,\n",
      "         5.6800e-03,  4.0251e-03, -5.1914e-03,  1.6196e-03,  1.6442e-03,\n",
      "         2.2091e-03,  6.0400e-03,  4.8771e-03,  2.8269e-03, -4.7013e-03,\n",
      "        -1.4931e-03,  1.6424e-03,  1.3790e-03, -5.3746e-03, -7.2548e-03,\n",
      "         2.9972e-03, -6.3980e-03,  4.1219e-03, -3.5226e-03,  2.2229e-03,\n",
      "         2.5907e-03, -3.5493e-03, -4.3811e-03,  9.1887e-03, -6.6273e-03,\n",
      "         1.1071e-03,  1.5460e-03,  1.4730e-03,  3.0230e-03,  5.7866e-03,\n",
      "        -3.6702e-03,  3.4311e-03,  1.1685e-03], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[-0.0018,  0.0086,  0.0018,  ..., -0.0009,  0.0045, -0.0039],\n",
      "        [ 0.0050,  0.0028,  0.0020,  ...,  0.0012, -0.0040,  0.0013],\n",
      "        [ 0.0023,  0.0050,  0.0038,  ...,  0.0037,  0.0045, -0.0049],\n",
      "        ...,\n",
      "        [-0.0028, -0.0040, -0.0017,  ..., -0.0029,  0.0067,  0.0013],\n",
      "        [-0.0013,  0.0030, -0.0012,  ..., -0.0028, -0.0020,  0.0012],\n",
      "        [ 0.0024,  0.0052,  0.0038,  ...,  0.0017, -0.0044, -0.0033]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([ 3.9799e-03, -6.7800e-03,  1.8419e-03,  3.1678e-03,  5.0904e-03,\n",
      "        -6.4126e-03,  3.0415e-03,  1.9760e-03, -2.6346e-03, -5.1245e-05,\n",
      "         7.5132e-03,  1.8882e-03,  3.2910e-03,  5.7509e-03,  3.2213e-03,\n",
      "         6.0825e-04,  6.1397e-03, -6.4840e-03, -2.3096e-03,  4.9250e-03,\n",
      "         4.1174e-03,  5.7318e-03,  1.6149e-03,  1.7891e-03,  5.3759e-03,\n",
      "         1.8203e-03, -3.9880e-03,  5.4595e-03,  3.9421e-03,  3.4643e-03,\n",
      "        -1.4606e-03, -3.1832e-03,  9.4830e-03,  2.4956e-03, -3.7498e-03,\n",
      "        -5.5731e-03, -6.0056e-04,  1.6603e-03,  4.9636e-04, -1.5880e-04,\n",
      "         5.3819e-03,  6.7612e-03,  3.8133e-04, -5.9123e-03,  2.5235e-03,\n",
      "        -4.4322e-03, -1.0704e-03,  3.4877e-03,  3.7453e-03,  4.9852e-03,\n",
      "         1.2291e-03,  5.5582e-03,  6.9012e-04,  2.1394e-03,  3.2920e-03,\n",
      "         4.1791e-03, -8.0532e-03, -2.6308e-05,  2.5371e-03,  1.8360e-03,\n",
      "         2.9603e-03, -4.4068e-03,  7.2738e-04,  4.7814e-03, -1.3707e-03,\n",
      "         5.8851e-03, -2.0550e-03, -9.8652e-04, -5.1531e-03,  1.5781e-03,\n",
      "         2.7199e-03, -4.4063e-03, -2.7675e-03, -5.0949e-03,  5.7825e-03,\n",
      "         3.0268e-03,  6.6370e-03, -2.9161e-03,  3.7163e-03,  2.5437e-03,\n",
      "        -5.0588e-03, -3.3566e-03,  4.7667e-03, -5.4977e-04, -2.8873e-03,\n",
      "         5.5807e-03,  2.1960e-03,  3.8914e-04,  4.1952e-03,  2.6553e-03,\n",
      "        -4.1025e-04, -3.7091e-03,  5.4976e-04, -6.2515e-03,  6.0324e-03,\n",
      "        -2.4571e-04,  3.6236e-03,  1.5337e-03,  6.0382e-03, -4.7910e-03,\n",
      "         8.7649e-04, -1.9652e-03,  2.4860e-03, -4.0632e-03,  2.0306e-03,\n",
      "        -4.6659e-03,  8.5873e-04,  6.1165e-03, -5.7839e-03, -1.8232e-03,\n",
      "         6.7217e-04,  1.7673e-05,  9.5908e-04, -6.7030e-03,  6.0740e-03,\n",
      "         6.4613e-03,  5.1940e-03, -6.7199e-03,  2.4791e-03, -2.8426e-03,\n",
      "         5.9239e-03,  7.7925e-04, -6.6630e-04,  2.8761e-03,  5.7717e-04,\n",
      "         4.6145e-03, -3.0547e-03, -4.5523e-03], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_enc = torch.load(RUN_FOLDER + '/models/encoder.pt')\n",
    "for i,j in zip(new_enc.parameters(), agent.actor_critic.encoder.parameters()):\n",
    "    print(i-j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0024,  0.0072,  0.0073,  ...,  0.0053,  0.0036,  0.0009],\n",
      "        [-0.0047,  0.0060,  0.0010,  ..., -0.0055, -0.0058,  0.0041],\n",
      "        [ 0.0032, -0.0078, -0.0050,  ...,  0.0012,  0.0025, -0.0014],\n",
      "        ...,\n",
      "        [-0.0012,  0.0022, -0.0024,  ..., -0.0013, -0.0030,  0.0009],\n",
      "        [-0.0031,  0.0065,  0.0051,  ..., -0.0034, -0.0041,  0.0027],\n",
      "        [-0.0026,  0.0015, -0.0018,  ..., -0.0056, -0.0065,  0.0035]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([-0.0044,  0.0059, -0.0024,  0.0026,  0.0015,  0.0019, -0.0040,  0.0028,\n",
      "         0.0030, -0.0021, -0.0050,  0.0037,  0.0034, -0.0022,  0.0045,  0.0037,\n",
      "        -0.0040, -0.0047, -0.0030,  0.0071,  0.0020,  0.0032, -0.0001,  0.0049,\n",
      "         0.0032,  0.0034,  0.0008,  0.0027, -0.0035, -0.0025,  0.0034, -0.0053,\n",
      "         0.0051, -0.0021,  0.0040, -0.0031, -0.0026,  0.0030, -0.0008, -0.0020,\n",
      "        -0.0034, -0.0015,  0.0056, -0.0031,  0.0031, -0.0044, -0.0063,  0.0048,\n",
      "         0.0045,  0.0032, -0.0021,  0.0064, -0.0026, -0.0030, -0.0029, -0.0053,\n",
      "        -0.0024, -0.0033,  0.0042,  0.0032,  0.0040, -0.0008,  0.0034,  0.0048,\n",
      "        -0.0013,  0.0037, -0.0057, -0.0022, -0.0043,  0.0011,  0.0046, -0.0036,\n",
      "         0.0062, -0.0016, -0.0064, -0.0048, -0.0034, -0.0026,  0.0046,  0.0030,\n",
      "         0.0032,  0.0031,  0.0028,  0.0046,  0.0042, -0.0042, -0.0058,  0.0016,\n",
      "         0.0040,  0.0043, -0.0036, -0.0036, -0.0043, -0.0036, -0.0036,  0.0033,\n",
      "         0.0028, -0.0073, -0.0017,  0.0018,  0.0039,  0.0032,  0.0014, -0.0025,\n",
      "         0.0026, -0.0017,  0.0018, -0.0029,  0.0028, -0.0008,  0.0042,  0.0042,\n",
      "         0.0037, -0.0023, -0.0052,  0.0038,  0.0025,  0.0057, -0.0042, -0.0007,\n",
      "         0.0035,  0.0025, -0.0038, -0.0058, -0.0048,  0.0026,  0.0053,  0.0061],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[ 0.0051, -0.0051, -0.0049,  ..., -0.0047, -0.0047, -0.0051],\n",
      "        [-0.0050,  0.0051,  0.0048,  ...,  0.0046,  0.0046,  0.0056],\n",
      "        [-0.0050,  0.0050,  0.0049,  ...,  0.0048,  0.0047,  0.0050],\n",
      "        ...,\n",
      "        [-0.0062,  0.0065,  0.0049,  ...,  0.0033,  0.0033,  0.0072],\n",
      "        [-0.0003,  0.0076,  0.0057,  ...,  0.0009,  0.0010, -0.0013],\n",
      "        [-0.0051,  0.0051,  0.0049,  ...,  0.0047,  0.0047,  0.0056]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([ 4.3455e-03, -3.9892e-03, -4.4713e-03,  1.5779e-03,  4.1275e-03,\n",
      "         4.3933e-03, -3.2667e-03,  4.4351e-03,  1.8061e-03, -2.0283e-03,\n",
      "        -4.4295e-03, -4.5241e-03,  3.4642e-04,  2.0444e-04,  2.6250e-03,\n",
      "        -4.2948e-03, -3.9580e-03,  4.7023e-04,  2.1215e-03, -4.2717e-03,\n",
      "        -2.1696e-03, -3.4551e-03, -4.3815e-03, -1.0407e-03, -4.4951e-03,\n",
      "        -4.7175e-03,  2.4893e-03,  3.8274e-03, -3.9181e-03, -4.2711e-03,\n",
      "         2.0975e-03,  4.2844e-03, -4.5372e-03, -4.3579e-03, -4.4095e-03,\n",
      "         4.3989e-03, -4.5029e-03,  1.0973e-03,  4.3471e-03, -3.5954e-03,\n",
      "        -9.6753e-04, -4.2102e-03,  4.3749e-03, -6.8889e-04, -4.9632e-03,\n",
      "        -6.7333e-03,  2.2687e-03,  4.4383e-03, -2.5472e-03,  4.2151e-03,\n",
      "        -4.9003e-04, -4.3299e-04, -4.5179e-03, -4.0953e-03, -3.3368e-03,\n",
      "         2.9377e-03,  4.3374e-03, -2.5449e-03,  4.4228e-03,  4.1181e-03,\n",
      "        -3.0181e-03, -3.7589e-03, -3.6723e-03,  4.5315e-03, -4.3727e-03,\n",
      "        -4.1151e-03, -3.4234e-03, -4.4994e-03,  3.2651e-03,  4.2936e-03,\n",
      "        -6.5889e-04,  3.0469e-03, -4.0663e-03,  3.1510e-03, -4.1198e-03,\n",
      "         1.5078e-03, -3.6824e-03,  1.1627e-03,  4.3956e-03, -3.9809e-03,\n",
      "         3.0834e-03,  3.4078e-03,  5.0880e-03,  4.4881e-03,  4.0827e-03,\n",
      "         6.1579e-03, -2.7688e-03,  4.5759e-03,  4.5453e-03, -4.5368e-03,\n",
      "         3.6537e-03, -3.8445e-03, -3.9675e-03, -4.1695e-04,  4.4725e-03,\n",
      "        -3.8759e-03, -1.0437e-03, -4.5437e-03, -1.9485e-03,  4.4241e-03,\n",
      "         3.5467e-03,  3.5666e-03,  3.5156e-03,  4.0315e-03, -5.6853e-03,\n",
      "         3.5384e-04, -3.3527e-03, -1.2191e-03, -3.9135e-03,  2.6406e-03,\n",
      "         1.0115e-03,  4.3930e-05,  4.5196e-03, -3.0947e-03,  8.6865e-04,\n",
      "        -1.3293e-03,  4.4041e-03, -3.3534e-03,  1.7648e-03, -4.3208e-03,\n",
      "        -2.9809e-03, -2.1134e-03, -3.2337e-03, -5.6467e-03,  8.7547e-04,\n",
      "        -7.2875e-04,  2.9749e-03, -4.2092e-03], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[ 0.0046,  0.0049, -0.0032, -0.0049, -0.0050, -0.0048,  0.0050, -0.0051,\n",
      "         -0.0050,  0.0050, -0.0044,  0.0050,  0.0050, -0.0049, -0.0050,  0.0048,\n",
      "         -0.0047,  0.0050,  0.0049, -0.0047,  0.0049,  0.0050,  0.0052, -0.0049,\n",
      "          0.0050,  0.0053,  0.0049,  0.0046,  0.0050,  0.0050, -0.0050, -0.0049,\n",
      "         -0.0048,  0.0050,  0.0052,  0.0046,  0.0053, -0.0050, -0.0050,  0.0051,\n",
      "         -0.0050,  0.0051,  0.0046,  0.0049, -0.0049,  0.0049,  0.0048,  0.0045,\n",
      "          0.0051, -0.0050,  0.0050,  0.0049, -0.0049,  0.0049,  0.0049,  0.0049,\n",
      "         -0.0050,  0.0049, -0.0051, -0.0050,  0.0050,  0.0050,  0.0051, -0.0054,\n",
      "          0.0051,  0.0050, -0.0048,  0.0054, -0.0050,  0.0046,  0.0051, -0.0050,\n",
      "          0.0050,  0.0049,  0.0052, -0.0050,  0.0050, -0.0050, -0.0051,  0.0049,\n",
      "         -0.0050,  0.0048, -0.0049, -0.0049,  0.0049, -0.0060,  0.0050, -0.0055,\n",
      "         -0.0054,  0.0051, -0.0050, -0.0049,  0.0050, -0.0050, -0.0052,  0.0050,\n",
      "          0.0050,  0.0054,  0.0049,  0.0044, -0.0050, -0.0050, -0.0050, -0.0050,\n",
      "         -0.0048, -0.0049,  0.0050,  0.0050, -0.0048, -0.0050,  0.0049, -0.0049,\n",
      "         -0.0052,  0.0050, -0.0050,  0.0050, -0.0050,  0.0050, -0.0050, -0.0047,\n",
      "          0.0051, -0.0049,  0.0051,  0.0047,  0.0048,  0.0049,  0.0049,  0.0049]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([-0.0044], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([-0.0071, -0.0031, -0.0008, -0.0022], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[-7.8070e-04,  1.5043e-03, -1.3714e-03,  2.1449e-03,  2.9603e-04,\n",
      "          1.9564e-03,  3.3897e-04,  3.7511e-04,  1.7810e-03, -2.5547e-03,\n",
      "         -8.5141e-04, -1.1682e-03,  1.0914e-03, -1.4142e-03,  2.1028e-03,\n",
      "          1.3810e-03, -2.9349e-04, -2.0403e-03, -3.8274e-04,  3.9697e-03,\n",
      "          2.3493e-03,  3.6357e-04, -1.4610e-03,  4.4764e-04,  3.1536e-04,\n",
      "          2.9960e-03,  2.7393e-03,  2.2449e-03, -2.7049e-03, -1.5152e-03,\n",
      "         -5.2072e-04, -7.4926e-04, -1.1483e-04,  1.8331e-04, -6.1850e-04,\n",
      "         -1.6293e-03, -6.2505e-04,  1.5003e-03,  8.2092e-04,  1.5995e-03,\n",
      "         -5.3988e-04,  1.3152e-03,  1.5133e-03, -2.3636e-03, -1.9632e-04,\n",
      "         -2.6808e-04, -2.2963e-03,  2.0215e-03,  1.6363e-03,  2.5272e-03,\n",
      "          1.6136e-03, -9.4386e-04,  1.2665e-04,  1.0386e-03, -2.5024e-04,\n",
      "         -2.1760e-03, -2.0391e-03, -3.2624e-04,  1.1663e-03,  2.3577e-04,\n",
      "          2.5504e-03,  1.1162e-03, -1.4785e-03, -9.6904e-04,  1.5105e-03,\n",
      "          4.0828e-03, -6.3983e-03, -3.1543e-04, -1.0323e-03,  1.3213e-03,\n",
      "          1.7969e-03,  1.4994e-03,  1.0421e-03, -5.9105e-04, -3.9795e-03,\n",
      "          4.3318e-04,  8.5641e-04, -1.7982e-03, -4.1122e-04,  9.8132e-04,\n",
      "          3.3225e-03,  1.1110e-03, -2.6862e-03,  1.1359e-03,  1.7067e-03,\n",
      "         -5.8142e-04,  9.1553e-04, -5.5603e-04, -8.9836e-04,  9.4980e-05,\n",
      "         -2.5252e-03, -1.6858e-03,  9.4372e-04, -7.7883e-04, -3.2870e-04,\n",
      "          7.3203e-04,  2.7189e-03, -3.2599e-03, -4.6207e-03, -7.2004e-04,\n",
      "          3.2852e-03,  1.2420e-03,  5.3890e-04, -1.1234e-03,  4.5996e-04,\n",
      "         -1.9724e-03,  1.8880e-05, -9.0450e-05, -1.4561e-04,  1.5649e-03,\n",
      "          2.0038e-03,  3.5753e-03,  1.9458e-03,  1.1041e-03, -1.6642e-03,\n",
      "         -1.5499e-04,  2.8246e-03, -1.0648e-03, -2.4516e-03, -1.5332e-03,\n",
      "         -4.2741e-04,  3.8655e-03, -2.4258e-03, -1.4792e-03, -2.2269e-03,\n",
      "         -2.2181e-03,  1.9703e-03,  2.3877e-03],\n",
      "        [-4.1090e-03,  2.7166e-03, -1.0449e-04,  5.0509e-03,  1.2583e-03,\n",
      "          4.1584e-03, -4.8062e-03,  1.5586e-03, -1.1595e-03, -6.5387e-03,\n",
      "         -9.5228e-04, -1.5350e-03,  4.6446e-03, -4.1141e-03,  1.9463e-03,\n",
      "          3.4638e-03, -5.5167e-03, -5.1990e-03,  2.3919e-03,  6.3562e-04,\n",
      "          3.2958e-03,  6.1981e-05, -9.3888e-04,  2.4048e-04,  3.6745e-04,\n",
      "          5.1989e-03, -5.9799e-04,  2.9639e-03, -3.8995e-03, -3.9547e-03,\n",
      "          1.6589e-03, -9.4722e-04, -9.8788e-04, -4.0465e-04, -1.6436e-04,\n",
      "         -4.6177e-03, -8.0238e-04,  1.8067e-03,  3.1898e-03, -4.4916e-03,\n",
      "         -4.6938e-03, -3.8111e-04,  2.1484e-03, -4.9265e-03,  8.7880e-05,\n",
      "         -1.3339e-03, -5.8898e-04,  4.8170e-04,  3.6592e-03,  3.5408e-03,\n",
      "          3.3049e-03,  6.5862e-04, -1.0216e-03, -2.6737e-03, -2.4952e-03,\n",
      "         -5.5499e-03, -7.0401e-03,  2.9031e-03,  3.0756e-03, -2.6280e-03,\n",
      "          8.2641e-03,  1.7338e-03,  3.3153e-03, -2.9575e-03, -6.2741e-04,\n",
      "         -1.6947e-03, -7.9744e-03, -6.2239e-03, -2.9615e-03,  2.4835e-03,\n",
      "          1.3819e-03, -3.1868e-03,  7.1158e-04, -3.6391e-03, -4.6741e-03,\n",
      "         -5.5451e-03, -4.8952e-03, -5.6947e-03, -5.4991e-04, -3.3784e-04,\n",
      "          7.2958e-03,  6.1094e-03,  9.3358e-03,  2.1991e-04,  1.7532e-03,\n",
      "         -4.0678e-04, -4.5295e-03,  7.5291e-04, -1.7578e-03,  1.4213e-03,\n",
      "         -5.1967e-03, -1.3539e-03, -5.7504e-03, -1.0340e-04, -7.3135e-04,\n",
      "          1.1798e-03,  3.4569e-03, -4.4198e-04, -8.0680e-03, -7.2320e-04,\n",
      "          3.3981e-03,  1.1284e-03, -2.6394e-03, -2.1454e-03,  5.6657e-03,\n",
      "         -1.6118e-03,  4.0165e-03, -4.1545e-03, -4.2033e-03, -1.6887e-03,\n",
      "          8.8566e-04,  3.6578e-03,  5.9155e-03,  3.8015e-03, -2.3756e-03,\n",
      "          2.6670e-03, -1.8369e-03,  4.7529e-03, -3.4854e-03, -1.6223e-03,\n",
      "         -2.0479e-03,  7.3684e-03, -1.7422e-03, -2.2929e-04, -5.0813e-03,\n",
      "          3.8869e-03,  1.0141e-03, -2.5148e-04],\n",
      "        [ 5.8844e-03, -2.1911e-03,  6.7610e-04, -4.2574e-03, -2.2894e-03,\n",
      "         -4.4886e-03,  2.8312e-03, -2.8413e-03,  1.9731e-03,  5.3073e-03,\n",
      "          4.6667e-03,  2.9818e-03, -4.3373e-03,  3.2446e-03, -1.6287e-03,\n",
      "          3.6432e-04,  6.5472e-03,  8.4994e-03, -2.2916e-03,  2.9168e-03,\n",
      "          2.9923e-04, -3.9136e-03, -2.8615e-03, -3.7050e-03, -1.2525e-03,\n",
      "         -6.4328e-03,  3.7081e-03, -5.2898e-03,  3.1735e-03,  4.7859e-03,\n",
      "         -2.9948e-03, -8.5174e-04,  2.2627e-03, -3.3418e-03,  4.2232e-03,\n",
      "          3.5838e-03, -3.4609e-03, -1.2423e-03, -3.9825e-03,  3.2554e-03,\n",
      "          4.7168e-03,  1.9919e-03, -4.3947e-03,  3.4833e-03, -4.4867e-03,\n",
      "         -1.7992e-04, -3.7132e-03,  3.9942e-03, -8.8900e-04, -1.4355e-03,\n",
      "         -1.3583e-03,  2.2540e-03,  4.5432e-03,  4.7411e-03,  3.3937e-03,\n",
      "          8.8910e-03,  4.5732e-03, -5.0518e-03, -6.4944e-03,  3.8047e-03,\n",
      "         -5.7165e-03, -4.5122e-03, -4.0445e-03,  3.2650e-03,  1.7598e-03,\n",
      "          1.4828e-03,  9.6674e-03,  4.8018e-03,  1.3860e-03, -4.6592e-03,\n",
      "          7.5758e-05,  4.7146e-03,  3.4734e-03,  4.3532e-03,  5.0772e-03,\n",
      "          3.3056e-03,  5.4409e-03,  2.8864e-03,  2.5535e-03,  4.2196e-03,\n",
      "         -5.4614e-03, -4.1505e-03, -4.8148e-03,  8.5642e-04, -4.7168e-04,\n",
      "         -2.1147e-03,  3.7812e-03, -1.3084e-03,  2.5602e-03, -2.4866e-03,\n",
      "          7.0382e-03, -3.6667e-03,  6.8592e-03, -9.6678e-04,  3.2375e-03,\n",
      "         -4.4436e-03, -2.4193e-03, -3.1425e-03,  3.6068e-03,  2.4322e-03,\n",
      "          1.1363e-03, -4.3758e-03,  3.5563e-03,  3.6184e-03, -3.1637e-03,\n",
      "          3.7731e-03, -3.7183e-03,  2.8713e-03,  4.1568e-03,  3.0009e-03,\n",
      "         -5.7158e-03, -1.5440e-03, -5.6859e-03, -2.6084e-03,  5.9491e-04,\n",
      "         -9.6452e-04,  2.0200e-03, -4.1656e-03,  5.3708e-03,  2.9717e-03,\n",
      "          6.4651e-03, -4.8828e-03, -1.0400e-04,  3.9146e-03,  4.1496e-03,\n",
      "          2.6245e-05,  4.1784e-04,  1.0640e-03],\n",
      "        [ 4.2446e-03, -2.6310e-03, -2.6480e-03,  1.6250e-03, -8.8752e-04,\n",
      "         -1.4319e-03,  4.3172e-03, -9.6211e-04,  4.6938e-03,  1.9852e-03,\n",
      "         -2.4504e-03,  8.9952e-04, -3.0702e-04,  5.1294e-03,  1.7966e-03,\n",
      "         -2.2869e-03,  3.9211e-03, -2.6244e-03, -4.1272e-03,  1.7683e-03,\n",
      "         -4.8725e-03,  1.1332e-03,  1.9555e-03,  2.2795e-03,  2.2776e-03,\n",
      "         -5.0029e-03, -3.8023e-04, -2.5413e-03,  3.3015e-04,  1.1156e-03,\n",
      "         -9.7778e-04, -4.1511e-04,  6.4894e-04,  1.7777e-03,  1.0608e-03,\n",
      "          3.7926e-03,  1.5488e-03,  2.3511e-03,  5.7311e-04,  6.1187e-03,\n",
      "          1.1280e-03,  6.7421e-04, -1.5370e-03,  9.3723e-04,  3.4134e-03,\n",
      "         -2.7269e-03, -1.1834e-03,  3.4869e-06,  4.8315e-04, -2.2483e-03,\n",
      "         -3.3294e-03,  2.9493e-03,  1.8390e-03,  1.2543e-04, -1.8452e-03,\n",
      "         -2.4616e-03,  4.5679e-03, -4.4999e-03, -4.9240e-03, -6.0305e-04,\n",
      "         -4.4897e-04, -1.8615e-03, -1.0034e-03,  3.7214e-03,  1.1366e-03,\n",
      "         -1.2080e-03, -1.4699e-03,  7.9339e-04,  2.0925e-03, -9.1973e-04,\n",
      "          2.7787e-03,  5.0975e-03, -8.4365e-04, -4.2111e-04,  5.0649e-04,\n",
      "         -6.4607e-03,  1.8600e-03,  7.7940e-04,  8.6316e-04,  1.2860e-03,\n",
      "         -1.0506e-03, -3.5582e-03, -9.0612e-05,  1.5596e-04, -3.5067e-04,\n",
      "         -1.9302e-04,  3.0824e-03, -1.3093e-03,  2.7635e-03, -8.9493e-04,\n",
      "          4.4347e-03, -2.3822e-03,  4.3727e-03, -1.2482e-03,  9.9100e-04,\n",
      "          1.3002e-03, -1.9552e-04, -1.4359e-03,  2.4699e-03,  4.2337e-04,\n",
      "         -5.8048e-04,  1.7803e-04,  1.4858e-03,  1.0936e-03, -4.4675e-03,\n",
      "          7.5822e-04, -9.4922e-04,  2.7584e-03,  4.3436e-03,  3.4235e-03,\n",
      "          4.8245e-04, -1.1838e-03, -3.0235e-04, -4.0514e-03,  3.4455e-03,\n",
      "         -3.0224e-03,  3.5122e-05, -4.1169e-03,  7.8894e-04,  1.1583e-03,\n",
      "          3.4661e-03, -4.2979e-03, -6.0417e-04, -1.6433e-03,  3.6601e-03,\n",
      "          7.5693e-03,  1.0657e-03,  1.3876e-03]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([ 0.0027,  0.0024, -0.0053, -0.0028], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_pol = torch.load(RUN_FOLDER + '/models/policy.pt')\n",
    "for i,j in zip(new_pol.parameters(), agent.actor_critic.policy.parameters()):\n",
    "    print(i-j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9229547103246054,\n",
       " 0.024201889013056643,\n",
       " 4.672254180908203,\n",
       " 1.9424843470255533)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.update(\n",
    "    storage,\n",
    "    encoder = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.actions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = [storage.latent[0].detach().clone()]\n",
    "latent[0].requires_grad = True\n",
    "\n",
    "h = storage.hidden_states[0].detach().reshape(1, 1, -1)\n",
    "test_hiddens = [h]\n",
    "for i in range(500):\n",
    "    # reset hidden state of the GRU when we reset the task\n",
    "    # print(storage.done[i+1])\n",
    "    h = agent.actor_critic.encoder.reset_hidden(h, storage.done[i])\n",
    "    # print(i, (h==storage.hidden_states[i:i+1]).sum())\n",
    "    # print(i, (torch.cat(latent[:i+1])-torch.cat(storage.latent[:i+1])).sum())\n",
    "    # update encoding\n",
    "    _, latent_mean, latent_logvar, h = agent.actor_critic.encoder(\n",
    "        storage.actions.float()[i:i + 1],\n",
    "        storage.next_state[i:i + 1],\n",
    "        storage.rewards_raw[i:i + 1],\n",
    "        h,\n",
    "        # storage.hidden_states[i:i+1],\n",
    "        sample=False,\n",
    "        return_prior=False,\n",
    "        detach_every=None\n",
    "        )\n",
    "    latent.append(torch.cat((latent_mean.clone(), latent_logvar.clone()), dim = -1).reshape(1, -1))\n",
    "    # _, tm, tl, h = agent.actor_critic.encoder(\n",
    "    #     storage.actions.float()[i:i + 1],\n",
    "    #     storage.next_state[i:i + 1],\n",
    "    #     storage.rewards_raw[i:i + 1],\n",
    "    #     h,\n",
    "    #     # storage.hidden_states[i:i+1],\n",
    "    #     sample=False,\n",
    "    #     return_prior=False,\n",
    "    #     detach_every=None\n",
    "    # )\n",
    "    # latent_sample.append(ts)\n",
    "    # tm = F.relu(tm)\n",
    "    # tl = F.relu(tl)\n",
    "    # latent.append(torch.cat((tm, tl), dim = -1))\n",
    "    # print(storage.latent[i] - latent[i])\n",
    "    test_hiddens.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### also some wrappers used \n",
    "# pop successes records the successes during training\n",
    "# randomisation settings - seems that they set all tasks at the start\n",
    "\n",
    "    # obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1)).to(device)[None,:,:]\n",
    "    # next_state = torch.from_numpy(np.append(next_obs, 0).reshape(1, -1)).to(device)\n",
    "    # reward = torch.from_numpy(np.array(reward).reshape(1, -1)).float().to(device)\n",
    "class ContinualEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Based on continual world env design:\n",
    "    https://github.com/awarelab/continual_world/blob/main/continualworld/envs.py\n",
    "    \"\"\"\n",
    "    def __init__(self, envs: List[gym.Env], steps_per_env: int):\n",
    "\n",
    "        ## good check to do\n",
    "        for i in range(len(envs)):\n",
    "            assert envs[0].action_space == envs[i].action_space\n",
    "\n",
    "        self.action_space = envs[0].action_space\n",
    "        self.observation_space = deepcopy(envs[0].observation_space)\n",
    "        # what is remove goal bounds? don't think need for meta-learning\n",
    "\n",
    "        self.envs = envs\n",
    "        self.num_envs = len(envs)\n",
    "        self.steps_per_env = steps_per_env\n",
    "        self.steps_limit = self.num_envs * self.steps_per_env\n",
    "        self.cur_step = 0\n",
    "        self.cur_seq_idx = 0\n",
    "\n",
    "    def _get_envs(self):\n",
    "        return self.envs\n",
    "\n",
    "    def step(self, action: Any) -> Tuple[np.ndarray, float, bool, Dict]:\n",
    "        # convert action to numpy\n",
    "        action = act.cpu().detach().numpy()[0]\n",
    "\n",
    "        # step\n",
    "        obs, reward, terminated, truncated, info = self.envs[self.cur_seq_idx].step(action)\n",
    "        done = terminated or truncated\n",
    "        info[\"seq_idx\"] = self.cur_seq_idx\n",
    "\n",
    "        self.cur_step += 1\n",
    "        if self.cur_step % self.steps_per_env == 0:\n",
    "            done = True\n",
    "            info[\"TimeLimit.truncated\"] = True\n",
    "\n",
    "            self.cur_seq_idx += 1\n",
    "        ## convert data to torch and put to device\n",
    "        obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1)).float().to(device)[None,:,:]\n",
    "        reward = torch.from_numpy(np.array(reward).reshape(1, -1)).float().to(device)\n",
    "\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        obs, _, self.envs[self.cur_seq_idx].reset()\n",
    "        obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1)).float().to(device)[None,:,:]\n",
    "        return obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metaworld\n",
    "import random\n",
    "\n",
    "ml10 = metaworld.ML10() # Construct the benchmark, sampling tasks\n",
    "\n",
    "training_envs = []\n",
    "for name, env_cls in ml10.test_classes.items():\n",
    "  env = env_cls()\n",
    "  task = random.choice([task for task in ml10.test_tasks\n",
    "                        if task.env_name == name])\n",
    "  env.set_task(task)\n",
    "  training_envs.append(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_envs(envs_to_do, num_episodes = 10, agent = None):\n",
    "\n",
    "    results = {i: dict() for i in range(len(envs_to_do))}\n",
    "    for i, env in enumerate(envs_to_do):\n",
    "        results[i] = evaluate_single_env(env, num_episodes, agent)\n",
    "        _, _ = env.reset()\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_single_env(env, num_episodes, agent):\n",
    "    results = {'episode_reward': [], 'success': []} \n",
    "    action = reward = hidden_state = None\n",
    "    for episode in range(num_episodes):\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        success = 0\n",
    "        episode_len = 0\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "        while not done:\n",
    "            if agent is not None:\n",
    "                obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1))[None,:,:].float().to(device)\n",
    "                if hidden_state is not None:\n",
    "                    reward = torch.from_numpy(np.array(reward).reshape(1, -1))[None,:,:].float().to(device)\n",
    "                    action = torch.from_numpy(action)[None, None,:].float().to(device)\n",
    "                _, act, hidden_state = agent.act(action, obs, reward, hidden_state)\n",
    "                action = act.cpu().detach().numpy()[0]\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "            next_obs, reward, truncated, terminated, info = env.step(action)\n",
    "            done = truncated or terminated\n",
    "            obs = next_obs\n",
    "\n",
    "            episode_reward += reward\n",
    "            success = info['success']\n",
    "            episode_len += 1\n",
    "\n",
    "            # stop on success for eval\n",
    "            if success == 1:\n",
    "                done = True\n",
    "\n",
    "        results['episode_reward'].append(episode_reward / episode_len)\n",
    "        results['success'].append(success)\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = evaluate_all_envs(training_envs, num_episodes = 10, agent = ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 EVALUATING\n",
      "10 1\n",
      "19 EVALUATING\n",
      "20 2\n",
      "29 EVALUATING\n",
      "30 3\n",
      "39 EVALUATING\n",
      "40 4\n",
      "49 EVALUATING\n",
      "50 5\n"
     ]
    }
   ],
   "source": [
    "## training loop\n",
    "# while the whole continual env is not done\n",
    "# train on each env sequentially\n",
    "# periodically evaluate on all envs\n",
    "\n",
    "agent = ActorCritic(policy_net, encoder_net)\n",
    "cont_env = ContinualEnv(training_envs, 10)\n",
    "eval_freq = 10\n",
    "num_steps = 0\n",
    "eval_results = dict()\n",
    "while cont_env.cur_step < cont_env.steps_limit:\n",
    "    # do each env\n",
    "    obs = cont_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        if agent is not None:\n",
    "            obs = torch.from_numpy(np.append(obs, 0).reshape(1, -1))[None,:,:].float().to(device)\n",
    "            if hidden_state is not None:\n",
    "                reward = torch.from_numpy(np.array(reward).reshape(1, -1))[None,:,:].float().to(device)\n",
    "                action = torch.from_numpy(action)[None, None,:].float().to(device)\n",
    "            _, act, hidden_state = agent.act(action, obs, reward, hidden_state)\n",
    "            action = act.cpu().detach().numpy()[0]\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        next_obs, reward, done, info = cont_env.step(action)\n",
    "        obs = next_obs\n",
    "\n",
    "        # periodically evaluate\n",
    "        if  (cont_env.cur_step + 1) % eval_freq == 0:\n",
    "            print(cont_env.cur_step, 'EVALUATING')\n",
    "            all_envs = cont_env._get_envs()\n",
    "            eval_results[cont_env.cur_step] = evaluate_all_envs(all_envs, num_episodes = 3)\n",
    "            eval_results[cont_env.cur_step]['task'] = cont_env.cur_seq_idx\n",
    "        \n",
    "    print(cont_env.cur_step, cont_env.cur_seq_idx)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_results(results_dict, _iter):\n",
    "    df = pd.DataFrame(results_dict[_iter])\n",
    "    task = np.unique(df.task).item()\n",
    "    res =df\\\n",
    "        .loc[:,[col for col in df.columns if col != 'task']]\\\n",
    "        .reset_index(\n",
    "            names = 'metric'\n",
    "        )\\\n",
    "        .melt(\n",
    "            id_vars = 'metric',\n",
    "            var_name = 'task'\n",
    "        )\\\n",
    "        .explode('value')\n",
    "    res.loc[:, 'iter'] = _iter\n",
    "    res.loc[:, 'current_task'] = task\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "res = pd.concat([unpack_results(eval_results, i) for i in eval_results.keys()])\n",
    "\n",
    "successes = res\\\n",
    ".query('metric==\"success\"')\\\n",
    ".groupby(['task', 'iter'])\\\n",
    ".agg(\n",
    "    {\n",
    "        'current_task':'max',\n",
    "        'value': lambda x: sum(x) / len(x)\n",
    "    }\n",
    ")\\\n",
    ".reset_index()\n",
    "\n",
    "rewards = res.query('metric==\"episode_reward\"')\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (15, 7))\n",
    "\n",
    "sns.lineplot(\n",
    "    data = rewards,\n",
    "    x = 'iter',\n",
    "    y = 'value',\n",
    "    hue = 'task',\n",
    "    ax = ax[0]\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = successes,\n",
    "    x = 'iter',\n",
    "    y = 'value',\n",
    "    hue = 'task',\n",
    "    ax = ax[1]\n",
    ")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(eval_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(df.iloc[0, 0], max_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k, [(i, pd.v) for i, v in v.items()]) for k, v in eval_results.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{'iter': k, 'value': pd.json_normalize(v)} for k, v in eval_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# example training\n",
    "### set the environment\n",
    "env = training_envs[0]\n",
    "### create a policy / actor critic\n",
    "# policy_net = torch.load(RUN_FOLDER + '/models/policy.pt')\n",
    "# we can update this\n",
    "actor_critic = model.Policy(\n",
    "    env.observation_space.shape,\n",
    "    env.action_space,\n",
    "    base_kwargs={'recurrent': True})\n",
    "actor_critic.to(device)\n",
    "\n",
    "\n",
    "### set algorithm\n",
    "ppo_agent = ppo.PPO(\n",
    "    actor_critic = actor_critic,\n",
    "    clip_param = 0.2,\n",
    "    ppo_epoch = 4,\n",
    "    num_mini_batch = 10,\n",
    "    value_loss_coef = 0.5,\n",
    "    entropy_coef = 1.0e-5,\n",
    "    lr = 1.0e-4,\n",
    "    eps = 0.99,\n",
    "    max_grad_norm = 0.5,\n",
    "    use_clipped_value_loss = False\n",
    ")\n",
    "\n",
    "## create rollouts\n",
    "rollouts = storage.RolloutStorage(\n",
    "    10, 1, env.observation_space.shape, env.action_space, actor_critic.recurrent_hidden_state_size\n",
    ")\n",
    "\n",
    "# don't know\n",
    "obs, _ = env.reset()\n",
    "rollouts.obs[0].copy_(torch.from_numpy(obs))\n",
    "rollouts.to(device)\n",
    "episode_rewards = deque(maxlen = 10)\n",
    "\n",
    "# actual training loop\n",
    "start = time.time()\n",
    "num_updates = 10\n",
    "for j in range(num_updates):\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            # this might be funny\n",
    "            value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(rollouts.obs[step], rollouts.recurrent_hidden_states[step], rollouts.masks[step], None)\n",
    "            step += 1\n",
    "\n",
    "        # step the env\n",
    "        obs, reward, truncated, terminated, info = env.step(action.detach().to('cpu').numpy()[0])\n",
    "        done = truncated or terminated\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varibad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
