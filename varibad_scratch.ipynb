{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metaworld\n",
    "# import environments.metaworld_envs\n",
    "import gym\n",
    "from environments.parallel_envs import make_vec_envs, make_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "\n",
    "from environments.env_utils.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from environments.env_utils.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from environments.env_utils.vec_env.vec_normalize import VecNormalize\n",
    "from environments.wrappers import TimeLimitMask, VariBadWrapper\n",
    "\n",
    "\n",
    "def make_env(env_id, seed, rank, episodes_per_task, tasks, add_done_info, **kwargs):\n",
    "    def _thunk():\n",
    "\n",
    "        env = gym.make(env_id, **kwargs)\n",
    "        if tasks is not None:\n",
    "            env.unwrapped.reset_task = lambda x: env.unwrapped.set_task(random.choice(tasks))\n",
    "        if seed is not None:\n",
    "            env.seed(seed + rank)\n",
    "        if str(env.__class__.__name__).find('TimeLimit') >= 0:\n",
    "            env = TimeLimitMask(env)\n",
    "        env = VariBadWrapper(env=env, episodes_per_task=episodes_per_task, add_done_info=add_done_info)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "def make_metaworld_env(env_id, task_id, seed, rank, episodes_per_task,add_done_info, **kwargs):\n",
    "    def _thunk():\n",
    "        env = gym.make(env_id, **kwargs)\n",
    "        env.set_benchmark_task(task_id)\n",
    "        if seed is not None:\n",
    "            env.seed(seed + rank)\n",
    "        if str(env.__class__.__name__).find('TimeLimit') >= 0:\n",
    "            env = TimeLimitMask(env)\n",
    "        env = VariBadWrapper(env=env, episodes_per_task=episodes_per_task, add_done_info=add_done_info)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_envs(env_name, seed, num_processes, gamma,\n",
    "                  device, episodes_per_task,\n",
    "                  normalise_rew, ret_rms, tasks,\n",
    "                  rank_offset=0,\n",
    "                  add_done_info=None,\n",
    "                  **kwargs):\n",
    "    \"\"\"\n",
    "    :param ret_rms: running return and std for rewards\n",
    "    \"\"\"\n",
    "    ## hacky work around\n",
    "    if 'ML10' in env_name:\n",
    "            envs = [make_metaworld_env(env_id=env_name, \n",
    "                    task_id = i,\n",
    "                    seed=seed, rank=rank_offset + i,\n",
    "                     episodes_per_task=episodes_per_task,\n",
    "                     add_done_info=add_done_info,\n",
    "                     **kwargs)\n",
    "            for i in range(num_processes)]\n",
    "    else:\n",
    "        envs = [make_env(env_id=env_name, seed=seed, rank=rank_offset + i,\n",
    "                        episodes_per_task=episodes_per_task,\n",
    "                        tasks=tasks,\n",
    "                        add_done_info=add_done_info,\n",
    "                        **kwargs)\n",
    "                for i in range(num_processes)]\n",
    "\n",
    "    if len(envs) > 1:\n",
    "        envs = SubprocVecEnv(envs)\n",
    "    else:\n",
    "        envs = DummyVecEnv(envs)\n",
    "\n",
    "    if len(envs.observation_space.shape) == 1:\n",
    "        if gamma is None:\n",
    "            envs = VecNormalize(envs, normalise_rew=normalise_rew, ret_rms=ret_rms)\n",
    "        else:\n",
    "            envs = VecNormalize(envs, normalise_rew=normalise_rew, ret_rms=ret_rms, gamma=gamma)\n",
    "\n",
    "    envs = VecPyTorch(envs, device)\n",
    "\n",
    "    return envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestML10Env(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        # initialise blank env\n",
    "        self.benchmark = metaworld.ML10()\n",
    "        self.task_names = list(self.benchmark.train_classes.keys())\n",
    "\n",
    "        # set a random task from the benchmark\n",
    "        self.set_task()\n",
    "\n",
    "        # requires self.set_task()\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "        # metaworld max steps - hardcoded\n",
    "        self._max_episode_steps = 500\n",
    "\n",
    "    def set_benchmark_task(self, task_id):\n",
    "        self.env_name = self.task_names[task_id]\n",
    "        self.env_cls = self.benchmark.train_classes[self.env_name]\n",
    "        self.env = self.env_cls()\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        info['task'] = self.task\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        obs, _ = self.env.reset()\n",
    "        return obs\n",
    "    \n",
    "    def get_task(self):\n",
    "        return self.env_name, self.env_cls\n",
    "    \n",
    "    ## reset_task is automatically created in make_env using set_task\n",
    "    def set_task(self, task = None):\n",
    "        if task is None:\n",
    "            task = random.choice(\n",
    "                [task for task in self.benchmark.train_tasks if task.env_name==self.env_name]\n",
    "                )\n",
    "\n",
    "        self.task = task\n",
    "        self.env.set_task(self.task)\n",
    "\n",
    "    # duplicated for varibad temporarily\n",
    "    def reset_task(self, task = None):\n",
    "        if task is None:\n",
    "            task = random.choice(\n",
    "                [task for task in self.benchmark.train_tasks if task.env_name==self.env_name]\n",
    "                )\n",
    "\n",
    "        self.task = task\n",
    "        self.env.set_task(self.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml10 = metaworld.ML10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reach-v2', 'push-v2', 'pick-place-v2', 'door-open-v2', 'drawer-close-v2', 'button-press-topdown-v2', 'peg-insert-side-v2', 'window-open-v2', 'sweep-v2', 'basketball-v2']\n",
      "pick-place-v2\n",
      "<class 'metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_pick_place_v2.SawyerPickPlaceEnvV2'>\n",
      "Task(env_name='pick-place-v2', data=b'\\x80\\x04\\x95=\\x01\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x08rand_vec\\x94\\x8c\\x15numpy.core.multiarray\\x94\\x8c\\x0c_reconstruct\\x94\\x93\\x94\\x8c\\x05numpy\\x94\\x8c\\x07ndarray\\x94\\x93\\x94K\\x00\\x85\\x94C\\x01b\\x94\\x87\\x94R\\x94(K\\x01K\\x06\\x85\\x94h\\x05\\x8c\\x05dtype\\x94\\x93\\x94\\x8c\\x02f8\\x94\\x89\\x88\\x87\\x94R\\x94(K\\x03\\x8c\\x01<\\x94NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00t\\x94b\\x89C0z9\\xbb\\x91\\x07\\xfc\\xb5?\\x8a\\xf1\\xbd\\xf0b\\x19\\xe6?\\x00\\x00\\x00@\\xe1z\\x94?;ll\\x0cPn\\xa4\\xbf\\xda,*\\xb0\\x9e\\x7f\\xea?N\\x1f[\\xc9\\xdd\\xfa\\xd1?\\x94t\\x94b\\x8c\\x07env_cls\\x94\\x8c8metaworld.envs.mujoco.sawyer_xyz.v2.sawyer_pick_place_v2\\x94\\x8c\\x14SawyerPickPlaceEnvV2\\x94\\x93\\x94\\x8c\\x14partially_observable\\x94\\x88u.')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "task_id = 2\n",
    "task_names = list(ml10.train_classes.keys())\n",
    "# env_name, env_cls = \n",
    "env_name = task_names[task_id]\n",
    "env_cls = ml10.train_classes[env_name]\n",
    "task = random.choice([task for task in ml10.train_tasks if task.env_name==env_name])\n",
    "print(task_names, env_name, env_cls, task, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ML10' in 'CustomML10-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml10_env = gym.make('ML10-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('ML10-v2')\n",
    "varibad_env = make_env('ML10-v2', 1, 1, 2, tasks = None, add_done_info =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbad_ml10 = varibad_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbad_ml10.done_mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00615235,  0.6001898 ,  0.19430117,  1.        , -0.03745555,\n",
       "        0.68238707,  0.01987216,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.00615235,  0.6001898 ,\n",
       "        0.19430117,  1.        , -0.03745555,  0.68238707,  0.01987216,\n",
       "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbad_ml10.reset_mdp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(40,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbad_ml10.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbad_ml10.episodes_per_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varibad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
